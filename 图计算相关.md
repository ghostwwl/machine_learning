# 图数据相关


- 图相关可以分为三块：
    - 可视化   --> 各种可视化工具  
    - 图计算   --> 图计算工具/框架
    - 图存储   --> 图数据库




- 图计算和图数据库的区别:
    - 负载方面
        - 图计算主要是 graph algorithms
        - 图数据库主要是 query，一般要提供查询语言
    - 输入方面
        - 图计算主要是 抽象图
        - 图数据库主要是 业务图
    - 时效性
        - 图计算一般是 大规模离线计算
        - 图数据库 往往 在线计算查询

        
  
- 图算法分类：
    - Neo4j 出了本书《Graph Algorithms: Practical Examples in Apache Spark and Neo4j》将图算法分为三类:
        - 遍历和寻路算法（Pathfinding）
            - 广度优先算法（BFS）
            - 深度优先算法（DFS）
            - 单源最短路径
            - 全源最短路径
            - 最小生成树（MWST）
            
        - 中心性评估（Centrality）
            - PageRank
            - 度中心性(Degree Centrality)
            - 接近中心性(Closeness Centrality)
            - 中介中心性(Betweenness Centrality)
            
        - 社区发现（Community Detection）
            - 标签传播(Label PropagaTIon)
            - 强连通(Strongly Connected)
            - 联合查找/连接组件/弱连接(Union-Find/Connected Components/Weakly Connected)
            - Louvain Modularity
            - 局部集聚系数/节点聚类系数(Local Clustering Coefficient/Node Clustering Coefficient)
            - 三角计数和平均聚类系数(Triangle-Count and Average Clustering Coefficient)
            - Connected Component
                > Connected Component算法可以称作连通子图算法，用于无向图中，即意图寻找这样的一些社群，社群与社群之间毫无联系，社群内部任意两个体存可达关系。该算法的时间复杂度是O(V + E)，V是节点数量，E是边的数量。下面这个图就存在三个连通子图（Component）
                ![img](http://blog.nsfocus.net/wp-content/uploads/2019/07/09a3168538ba340db1aa0d8ee3ecac42.png)

    - 其它分法：
        - 图评估类算法
            - 节点评估类
            - 边评估类
            - 聚类评估类

        

## 一. 图计算框架

- Pregel & Giraph
- Giraph
- GraphX/GraphFrame
- GrpahLab/PowerGrah/GraphChi
- Gemini
- PandaGraph
- Plato


### 图数据开发包

如果我们要在代码中处理图数据结构:
- Boost库（一个大名鼎鼎的C++库）中包含的专门面向图计算的BGL（Boost Graph Library）和PBGL（Parallel Boost Graph Library）
    - BGL提供了用于表示图的数据结构以及一些常用的图分析算法；
    - PBGL则扩展了BGL，在此之上基于MPI提供了并行/分布式计算的能力。
- CGMgraph与PBGL类似，基于MPI(并行计算)提供了一系列图分析算法的并行/分布式实现



### 0x0. Pregel & Giraph

#### 简介:

2010年出来的Google 提出了 Pregel 来解决图算法在 MapReduce 上运行低效的问题，但没有开源。  
Giraph 由 Yahoo 开源，原型是 Google 的 Pregel，在 2012 年已经成为 Apache 软件基金会的开源项目，并得到 Facebook 的支持  
Giraph 有两个问题：一是 Giraph 的社区不是很活跃；  
二是现实生活中的图都是符合幂律分布的图，即有一小部分点的边数非常多，这些点在 Pregel 的计算模式下很容易拖慢整个计算任务。  
  
Giraph基于Hadoop而建，将MapReduce中Mapper进行封装，未使用reducer。  
在Mapper中进行多次迭代，每次迭代等价于BSP模型中的SuperStep。  
一个Hadoop Job等价于一次BSP作业 

#### 特点:
- 支持大图，毕竟是facebook自己要用的
- 顶点为中心（vertex-centric）的图计算编程模型
    - 将算法的每一轮迭代抽象为从单个顶点的角度考虑需要完成的计算过程，即用户自定义的顶点程序（vertex programs）
    - 每个顶点有两种状态：
        - 活跃和非活跃
        - 每轮迭代中只有活跃顶点需要参与计算  
- 使用消息传递（message passing）模型在顶点之间通信：
    - 用户可以在顶点程序中让一个顶点向其它顶点（通常是邻居）发送消息；
    - 根据收到的消息，顶点可以更新自己的状态以及计算相关的数据。
- 以顶点为中心的程序抽象
    - 可以非常容易地以顶点为基本处理单元
- 同步计算模式
    - 使用BSP（Bulk Synchronous Parallel）模型并行/分布式处理，将图计算从单线程扩展到多核进而多机上
- 与MapReduce相比，Pregel不仅提供了面向图的编程模型，更重要的是针对图算法通常需要迭代式计算的特点，避免了需要反复将中间结果序列化到磁盘的不必要开销
    - 实际上出于容错考虑，有时依然需要在迭代开始前将中间结果保存到磁盘上。
    - 然而，我们可以根据集群的实际情况，每隔若干轮进行一次保存，或是根据算法的特点，仅保存一部分关键信息（其它信息可能是只读的，或是可以通过这些进行恢复）。
 


### 0x1. GraphX

2014年推出嵌入式图形理平台，GraphX。它构建在Apache Spark之上，用于并行计算，最早是伯克利 AMPLAB 的分布式图计算框架项目，后来整合到 Spark 中成为一个核心组件  
GraphX 是基于 Spark 构建的图计算系统，融合了很多 PowerGraph 的思想，并对 Spark 在运行图算法过程中的多余 Shuffle 进行了优化。  
GraphX 是 Spark 中用于图和图并行计算的 API，其实是 GraphLab 和 Pregel 在 Spark(Scala) 上的重写及优化，跟其他分布式图计算框架相比  
GraphX 最大的优点，在 Spark 之上提供一栈式数据解决方案，可以方便且高效地完成图计算的一整套流水作业  
GraphX 对比原生 Spark 在性能方面有很大优势，但 GraphX 非常费内存，Shuffle 效率也不是很高，导致运行时间也比较长。 
Spark那个RDD抽象导致GraphX非常费内存  

- GraphX基于 [BSP模型]
- 淘宝在用
- facebook 对比过Apache Giraph的出的结论是： GraphX可以使图数据处理解决方案的开发更简单
- GraphX支持以SQL样式的查询从Hive中读取图，支持任意列转换。使用shell环境中的Scala是一种测试GraphX简单应用的简便方式

- http://blog.sina.com.cn/s/blog_628cc2b70102ycxb.html
- https://www.open-open.com/lib/view/open1420689305781.html


### 0x2. GraphFrames

Databricks和UC Berkeley及MIT一起为Apache Spark设计了一个图处理库——GraphFrames。
它既能利用DataFrame良好的扩展性和强大的性能，同时也为Scala、Java和Python提供了统一的图处理API

与GraphX类似，GraphFrames支持多种图处理功能，但得益于DataFrame因此GraphFrames与GraphX库相它有着下面几方面的优势：  
统一的 API: 为Python、Java和Scala三种语言提供了统一的接口，这是Python和Java首次能够使用GraphX的全部算法。  
强大的查询功能：GraphFrames使得用户可以构建与Spark SQL以及DataFrame类似的查询语句。  
图的存储和读取：GraphFrames与DataFrame的数据源完全兼容，支持以Parquet、JSON以及CSV等格式完成图的存储或读取。  
兼容GraphX算法，GraphFrames还加入了广度优先搜索BFS和模式发现Motif finding两种新算法  
GraphFrames可以实现与GraphX的完美集成。两者之间相互转换时不会丢失任何数据  
在GraphFrames中图的顶点(Vertex)和边(edge)都是以DataFrame形式存储的，所以一个图的所有信息都能够完整保存。  

- https://spark-packages.org/package/graphframes/graphframes
- 安装
    > $SPARK_HOME/bin/spark-shell --packages graphframes:graphframes:0.7.0-spark2.4-s_2.11
    
    
### 0x3. GraphLab/PowerGraph/GraphChi

#### 简介

- GraphChi 出自 GrpahLab
    - 第一个实现将大规模图数据处理搬到普通PC上的系统
    - GraphChi的编程模型与GraphLab类似，并同样采用了异步的计算模式
    - 提出PSW（Parallel Sliding Windows）处理模型
- [十分钟了解 GraphLab](https://www.cnblogs.com/wei-li/p/GraphLab.html)
- 集成HDFS。GraphLab 内置对HDFS 的支持，GraphLab 能够直接从HDFS中读数据或者将计算结果数据直接写入到HDFS 中
- PowerGraph的突出贡献是提出了基于顶点分割（vertex-cut）[3]思想的图数据划分方法，并将顶点程序分成了三个步骤——收集信息（Gather）-更新状态（Apply）-分发信息（Scatter）（又称GAS模型）
- 将顶点程序分成了三个步骤 －－＞ 更好地应对实际图数据容易导致的计算/通信不均衡
    - GAS计算模式
        - 收集信息（Gather）
        - 更新状态（Apply）
        - 分发信息（Scatter）
- GraphLab是最早由卡耐基梅隆大学SELECT实验室于Pregel同时期推出的图计算系统

GraphLab 是一个机器学习平台，主要是图模型方面的计算。  
GraphLab 是另一种有趣的MapReduce抽象实现，侧重机器学习算法的并行实现。GraphLab中，Map阶段定义了可以独立执行（在独立的主机上）的计算，Reduce阶段合并这些计算结果。
设计和实施有效且可证明正确的并行机器学习（ML）算法可能非常具有挑战性。 现有的高级并行抽象（如MapReduce）通常无法充分表达，而低级工具（如MPI和Pthreads）则使ML专家反复解决相同的设计难题。通过针对ML中的常见模式，开发了GraphLab，它通过紧凑地表达具有稀疏计算依赖性的异步迭代算法，同时确保数据一致性并实现高度的并行性能，从而改进了MapReduce之类的抽象性。

![img](https://static.oschina.net/uploads/space/2012/1213/074439_tlSt_12.png)
![img](http://static.oschina.net/uploads/space/2012/1213/074446_qIAX_12.png)


#### 特点
- 比Giraph和GraphX都要快
- GraphLab主要面向机器学习/数据挖掘问题
    - 针对很多这类算法需要在稀疏数据上进行迭代式计算的特点
- GraphLab把输入/输出数据以图的形式进行表示
- 算法抽象为图上的计算过程
- 与 Pregel 一样以顶点为中心的图计算模型



### 0x4. Gemini

- 费马科技的图计算产品PandaGraph的前身
- Gemini 是 16 年发表再在 OSDI 的一篇图计算系统论文，结合了多种图计算系统的优势，并且有开源实现，作为最快的图计算引擎之一，得到了业界的普遍认可
- 比较前沿的，Gemini 团队也成立了商业公司专注图数据的处理，阿里、腾讯、字节　也有相关跟进
- 正如《Scalability! But at what COST? 》一文指出，多数的图计算系统为了拓展性，加之分布式带来的巨大通信开销，导致多机环境下的计算性能有时甚至反而不如单机环境。针对这些问题，Gemini 的做了针对性优化设计，简单总结为：
    - 图存储格式优化内存开销：采用 CSC 和 CSR 的方式存储图，并对 CSC/CSR 进一步建立索引降低内存占用
        - [实例讲解coo/csc/csr稀疏矩阵存储原理](https://cf.jd.com/pages/viewpage.action?pageId=332303195)
    - Hierarchical Chunk-Based Partitioning：通过在 Node、Numa、Socket 多个维度做区域感知的图切分，减少通信开销
    - 自适应的 Push / Pull 计算：采用了双模式通信策略，能根据当前活跃节点的数量动态地切换到稠密或稀疏模式

- Gemini采用了块式划分的策略
    - 让每台机器负责一段连续区间的顶点，从而尽可能减少分布式相关的开销

- Gemini抛弃了传统分布式图计算系统以图划分质量为优化方向的观念，提出了以计算为中⼼的设计原则：
    - 尽可能地避免分布式引入的开销；
    - 尽可能地提升计算部分的效率。
     

- 分布式图计算系统会损失大量性能的原因，主要可以归结于两方面：
    - 过于重视通信和负载均衡带来的影响；
    - 忽略了分布式场景下计算部分的影响。
    
- PandaGraph是Gemini的商业化版本（费马科技的创始人中包括了Gemini的主要作者），在Gemini开源版的基础上增加了大量功能，例如：
    
- 论文地址：https://www.usenix.org/system/files/conference/osdi16/osdi16-zhu.pdf
- 源码地址：https://github.com/thu-pacman/GeminiGraph
- 公开PPT：https://myslide.cn/slides/3004



## 0x5. PandaGraph

- 北京费马科技有限公司
    - 创始人中包括了Gemini的主要作者
    - https://fma-ai.cn/product/
    - 产品
        - TuGraph图数据库 通过中国信通院大数据产品能力评测
        - PandaGraph 图分析引擎
    

PandaGraph是Gemini的商业化版本，在Gemini开源版的基础上增加了大量功能，例如：

- 与Hadoop生态系统的集成，包括：
    - 面向HDFS的输入/输出接口，文本格式文件的解析接口等；
    - 支持YARN来调度PandaGraph程序；
    - 基于MapReduce/Spark的预处理/后处理方案等；

- 部分组件的进一步优化，包括：
    - 更节省的内存空间使用；
    - 更鲁棒的通信效率；
    - 更快的图数据载入/划分等；
    - 以及更多的算法实现等

![img](https://fma-ai.cn/_nuxt/img/ed079c7.png)



### 0x6. Tencent Plato

Tencent Plato是基于 Gemini 思想的开源图计算系统，采用了 Gemini 的核心设计思路，它认为原有的主流图计算开源框架的如果要完成超大规模数据的图计算，
需要花费超长的时间或者需要大量的计算资源。
而许多真实业务场景要求超大规模图计算必须在有限时间和有限资源内完成。因此Plato致力于提供超大规模图数据的离线图计算和图表示学习。
它的特点是计算能力强、内存消耗较小（只选取了Plato与Spark GraphX在PageRank和LPA这两个benchmark算法的性能对比），
并且为开发者同时提供了底层API和应用层的接口工具。

- 据说是: 加州大学、清华大学、北京大学等世界知名学府组成的高性能计算团队的努力下产出的
    
    
### 0x7. Ligra

Ligra是用于共享内存的轻量级图形处理框架。它特别适用于实现并行图遍历算法，其中在迭代中仅处理一部分顶点。
该项目的基本观点是最大的公开可用的现实世界图形都适合共享内存。当图形适合共享内存时，与分布式内存图形处理系统相比，
使用Ligra处理图形可以将性能提高多达几个数量级。


## 各大厂商的情况

- 华为
    - 熟悉大数据开发平台（Spark/Hadoop/GraphLab/GraphChi/Parameter Server/TensorFlow）
- 字节跳动 
    - 字节跳动自研万亿级图数据库 & 图计算实践
        - 基于 Gemini 
        - 对外是这么说，但是他们的招聘信息里要求 GraphLab/GraphCHI 是不是说明了点什么
        - https://www.6aiq.com/article/1583079309385
    - ByteGraph （go + 分布式kv)
        - vertex
            - 点的id(uint64_t): 比如用户id作为一个点
            - 点的type(uint32_t): 比如appID作为点的type
            - 点的属性（KV 对）：比如 'name': string，'age': int, 'gender': male，等自定义属性
            - [id, type]唯一定义一个点
        - edge
            - 两个点（Vertex）: 比如用户A和用户B
            - 边的类型(string): 比如“关注”
            - 边的时间戳(uint64_t)：这个t值是业务自定义含义的，比如可以用于记录关注发生的时间戳
            - 边属性（KV对）：比如'ts_us': int64 描述关系创建时间的属性，以及其他用户自定义属性
        - 边的方向
            - 正向边：如 A 关注 B(A -> B)
            - 反向边：如 B 被 A 关注(B <- A)
            - 双向边：如 A 与 B 是好友(A <-> B)
    - 机器学习/深度学习：Spark MLib，GraphLab/GraphCHI，Angel，MXNet，TensorFlow，Caffe, Xgboost，VW，libxxx；
- 腾讯
    - Plato 多方一起搞的




![img](http://blog.nsfocus.net/wp-content/uploads/2019/07/bf1c3d5eee77028eb413591ac303702c.png)

![img](https://bbs.cvmart.net/uploads/images/201910/25/19/nd77l3hC6e.png?imageView2/2/w/1240/h/0)


将来的趋势:
- 动态图计算
- 


相关术语介绍:

- [BSP模型](https://baike.baidu.com/item/BSP%E6%A8%A1%E5%9E%8B/1012261)  
    - BSP(Bulk Synchronous Parallel，整体同步并行计算模型)是英国计算机科学家Viliant在上世纪80年代提出的一种并行计算模型。
    - 一个 BSP 并行计算机由一组通过通讯网络互连的处理器——内存单元组成。它主要有三个部分:
        - 一组具有局 部内存的分布式处理器
        - 全局数据通讯 网络 
        - 支持所有处理单元间全局路障同步的机制
        
1.Processors指的是并行计算进程，它对应到集群中的多个结点，每个结点可以有多个Processor；  
2.LocalComputation就是单个Processor的计算，每个Processor都会切分一些结点作计算；  
3.Communication指的是Processor之间的通讯。接触的图计算往往需要做些递归或是使用全局变量，在BSP模型中，对图结点的访问分布到了不同的Processor中，并且往往哪怕是关系紧密具有局部聚类特点的结点也未必会分布到同个Processor或同一个集群结点上，所有需要用到的数据都需要通过Processor之间的消息传递来实现同步；  
4.BarrierSynchronization又叫障碍同步或栅栏同步。每一次同步也是一个超步的完成和下一个超步的开始；  
5.Superstep超步，这是BSP的一次计算迭代，拿图的广度优先遍历来举例，从起始结点每往前步进一层对应一个超步。  
6.程序该什么时候结束呢？这个其实是程序自己控制，一个作业可以选出一个Proceessor作为Master，每个Processor每完成一个Superstep都向Master反馈完成情况，Master在N个Superstep之后发现所有Processor都没有计算可做了，便通知所有Processor结束并退出任务
  
        
- [GAS计算模式](https://www.jianshu.com/p/f088bf589820)
    - GAS模型主要分为3个阶段：Gather Apply Scatter
        - Gather阶段的主要工作主要发生在各个计算节点，搜集这个计算节点图数据中某个顶点的相邻边和顶点的数据进行计算（例如在PageRank算法中计算某个顶点相邻的顶点的数量）
        - Apply阶段的主要工作是将各个节点计算得到的数据（例如在PageRank算法中各计算节点计算出来的同一节点的相邻节点数）统一发送到某一个计算节点，由这个计算节点对图节点的数据进行汇总求和计算，这样就得到这个图顶点的所有相邻节点总数
        - Scatter阶段的主要工作是将中心计算节点计算的图顶点的所有相邻节点总数发送更新给各个计算节点中，这些收到更新信息的节点将会更新本计算节点中与这个图顶点相邻的顶点以及边的相关数据

- [vertex-cut（顶点分割）]  
传统的图划分方法以顶点为划分单元，顶点和所属的边放在一起；  
顶点分割则以边为划分单元，一个顶点的边可以归属到不同的分区（partition）。  
显然，后者的粒度更细，更容易解决负载均衡方面的问题；  
对应的一个劣势是顶点的状态需要在不同分区上进行复制（replication），占用的内存空间相对更大。  


参考资料：
- [Gemini: A Computation-Centric Distributed Graph Processing System](https://www.usenix.org/conference/osdi16/technical-sessions/presentation/zhu)
- [图计算系统发展简史1](https://zhuanlan.zhihu.com/p/77740015)
- [图计算系统发展简史2](https://zhuanlan.zhihu.com/p/79169412)
- [图计算系统发展简史3](https://zhuanlan.zhihu.com/p/80455017)
- [图计算系统发展简史4](https://zhuanlan.zhihu.com/p/83202666)
- https://zhuanlan.zhihu.com/p/158572726
