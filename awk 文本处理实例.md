# awk 实例

### awk 里的常量
- `ARGC` 命令行变元个数 
- `ARGV` 命令行变元数组 
- `FILENAME` 当前输入文件名 
- `FNR` 当前文件中的记录号 
- `FS` 输入域分隔符，默认为一个空格 
- `RS` 输入记录分隔符 
- `NF` 当前记录里域个数 	---> $(NF-3) 倒数第四个域
- `NR` 到目前为止记录数  --> 当前行号
- `OFS` 输出域分隔符 
- `ORS` 输出记录分隔符

### 简单使用
#### 1. 模式匹配
awk '/zqy/' fileA #寻找出fileA中含有zqy的行 等同于awk '$0~/zqy/' fileA
awk '$1~/88/' fileA #找出第一个域里面包含88的行
awk '$1~/88/{print $2}' fileA #找出第一个域里面包含88的行后，只打印该行的第二个域


#### 2. 简单计算
- 求和
> cat data|awk '{sum+=$1} END {print "Sum = ", sum}'
 
- 求平均
> cat data|awk '{sum+=$1} END {print "Average = ", sum/NR}'
 
- 求最大值
> cat data|awk 'BEGIN {max = 0} {if ($1>max) max=$1 fi} END {print "Max=", max}'
 
- 求最小值（min的初始值设置一个超大数即可）
> awk 'BEGIN {min = 1999999} {if ($1<min) min=$1 fi} END {print "Min=", min}'


#### 统计文本分类的标本
```shell

# 按照空格分割 如果标本分词后 只有单个词的 打印出标本的行号和标本
cat category20171109.corpus|awk '{corpus_len=split($0, a, " ");if(corpus_len<3)print  "line:" NR " " $0;}'
# 按照空格分割 如果标本分词后 只有单个词的 打印标本里的唯一词条
cat category20171109.corpus|awk '{corpus_len=split($0, a, " ");if(corpus_len<3)print  "line:" NR " " a[2];}'
# 按照空格分割标本 如果标本只包含一个词并且这个词是单个数字或字母字符的 打印出标本的行号和标本
cat category20171109.corpus|awk '{corpus_len=split($0, a, " ");if(corpus_len<3 && a[2] ~ /^[0-9a-zA-Z]{1}$/)print  "line:" NR " " $0;}'

```


### 根据文件内容删除文件
- 文件内容为 `not found` 的文件给删掉
> ` awk '$0 == "not found"{print FILENAME}' *.json|xargs rm -f `

- 统计百科标签分布  

假设文件格式 第一列 词条 第二列 标签多个逗号隔开 

```text
阿胶补血膏      中药,科学百科药物分类   应用科学,药物中文名称列表,药物列表,2010年批准药品,补益类,国产药品,健康科学,科学,药品,补益类中成药,药物,中药,煎膏剂应用科学,药物中文名称列表,药物列表,2010年批准药品,补益类,国产药品,健康科学,科学,药品,补益类中成药,药物,中药,煎膏剂
阿胶补血口服液  中药    西药,补益类,药物列表,药物中文名称列表,应用科学,国产药品,科学,药品,中成药,2009年批准药品,补益类中成药,合剂,药物,中药                             西药,补益类,药物列表,药物中文名称列表,应用科学,国产药品,科学,药品,中成药,2009年批准药品,补益类中成药,合剂,药物,中药
阿胶当归合剂            补益类,2010年批准药品,应用科学,国产药品,科学,药品,中成药,补益类中成药,合剂,中药,调经止带类中成药                                补益类,2010年批准药品,应用科学,国产药品,科学,药品,中成药,补益类中成药,合剂,中药,调经止带类中成药
阿胶粉          美容养颜,润惠堂,阿胶,阿胶粉,滋补国宝                    阿胶原粉，是以阿胶原液为原料，采用真空干燥技术成粉，入口喷香，入水易化，最适于加蜂蜜、牛奶、奶粉、红茶等伴侣做成各式各样的时尚养生茶饮。        美容养颜,润惠堂,阿胶,阿胶粉,滋补国宝
阿胶膏  医学,中药       中医,中药,食疗养生,健康,药食同源                        阿胶味甘、性平，归三经，阿胶膏有补气养血，滋阴润肺。美容养颜、改善睡眠。调经安胎、消除女性各种周期不适等症状，阿胶最好的吃法就是做成阿胶膏，味道好，营养全，方便携带。阿胶膏属于中国传统药膳食疗中的膏滋类，又称膏方，阿胶属于中医动物类药材，两者具有不同的概念。      中医,中药,食疗养生,健康,药食同源



结果:
-------------------
医学    3641
茶      3827
旅游    4007
科学百科药物分类        4916
中药    6684
科学    7043
休闲食品        7493
饮品    7804
生活    35941
菜品    168829
食品    182597

```
> `awk -F "\t" '{tagcount=split($2, tags, ",");for(i in tags) c[tags[i]]++}END{for (i in c) print i"\t"c[i]}' info.txt |sort -n -k2`

- 文本按 '\t' 分割 然后取第二列 把他按','分割 遍历结果 放入 一个hash 统计频率 然后 输出 按照第二列升序排列  



### 如果两个文件行数相同，只是希望逐行合并

- 方法一
    > `$ paste -d "\t" file_1 file_2`

- 方法二
    > `$ awk 'NR==FNR{a[NR]=$0;nr=NR;}NR>FNR{print a[NR-nr]"\t"$0}' file_1 file_2`

- 方法三
    > `$ awk '{getline f2 < "file_2"; print $0"\t"f2}' file_1`

### 两个文件之间单纯求记录交集

- 方法一（需要先去除重复记录，两个文件的格式必须相同，尤其要注意每行结尾的空格，换行符）
    > `$ sort file_1 file_2 |uniq -d`                                                                                                                                                                                                                                                                                                                                                                                                        - 方法二（file_1大于file_2的记录数，不适合记录过多的文件，也需要提前去重复）
    > `$ grep -w -f file_1 file_2|sort|uniq`

两种方法可以一起用，从而检查结果是否准确

- 方法三（如果需要匹配超过两个的文件，就修改“==2”的数值为文件个数）
    > `$ awk '!b[$1,ARGIND]++{if(++a[$1]==2)print}' file_1 file_2`


### 累加第二列的数值

- 方法一（无条件累加）
    > `$ awk '{a=a+$2}END{print a}' file`

- 方法二（若第三列的内容相同，则累加对应记录的第二列数值）
    > `awk '{a[$3]+=$2}END{for(i in a) printf "%s\t %d\n",i,a[i]}' file`

- 方法三（对其他列的内容进行限制筛选以后累加第二列的数值）
    > `$ awk '$4=="abc" && $5>=100 && $6<=500{a=a+$2}END{print a}' file`

- 方法四（若第三列，第四列内容相同，则累加第二列的数值，并将结果升序输出）
    > `$ awk '{a[$3,"\t",$4]+=$2}END{for(i in a)printf "%s\t %d\n",i,a[i]}' file|sort`
 
 
### 我手头上有好几个个文件,他们的格式都是一样的,如果我想求他们的交集,并且如果1、2、3、6、7列都相同,则输出其文件名“\t"$0.我尝试用awk去做,可是结果并不齐全.应该怎么做呢?

~~~awk

awk -vD=',' '{if(F!=FILENAME)f++;F=FILENAME;n=$1D$2D$3D$6D$7;a[n]=a[n]F" "$0"\n";c[n]++}END{for(n in c)if(c[n]==f)printf("%s",a[n])}' filter_wl.txt filter_ly.txt filter_ly1.txt

~~~


### 一行多个词 
nohup cat result_spuppos.txt|awk -F "\t" '{products_count=split($2, words, ", "); for (i in words) x[words[i]]++;}END{for (j in x) print j"\t"x[j];}' > spu_cw.txt &


### 

原始文本类型：
~~~
[('凉鞋', 3), ('一字扣带', 1), ('裙子', 1), ('鞋子', 3),'凉鞋', '鞋子']
[('凉拖鞋', 3), ('凉鞋', 3), ('室外', 1),'凉拖鞋', '凉鞋']
[('九分裤', 3), ('牛仔裤', 3), ('裤子', 3),'九分裤', '牛仔裤', '裤子']
[('短袖', 3), ('t恤', 3), ('刺绣', 1), ('上衣', 3), ('打底衫', 3), ('汉服', 3), ('男装', 1),'短袖', 't恤', '上衣', '打底衫', '汉服']
[('丝光棉', 1), ('刺绣', 1), ('短袖', 3), ('t恤', 3), ('长裤', 3),'短袖', 't恤', '长裤']
[('牛仔裤', 3), ('男裤', 3), ('直筒裤', 3), ('长裤', 3),'牛仔裤', '男裤', '直筒裤', '长裤']
[('卫衣', 3), ('短袖', 3), ('t恤', 3),'卫衣', '短袖', 't恤']
[('蝴蝶结', 1), ('拖鞋', 3), ('凉拖', 3),'拖鞋', '凉拖']
[('护士鞋', 1), ('洞洞鞋', 3), ('凉鞋', 3), ('凉拖鞋', 3),'洞洞鞋', '凉鞋', '凉拖鞋']
[('豆豆鞋', 3), ('男鞋', 3),'豆豆鞋', '男鞋']
~~~

需要结果 整个文件里 所有的词出现的次数  按照从多到少排序
~~~
 凉鞋   6
 短袖   6
 t恤    6
 牛仔裤         4
 凉拖鞋         4
 长裤   4
 直筒裤         2
 鞋子   2
 卫衣   2
 拖鞋   2
 上衣   2
 男鞋   2
 男裤   2
 凉拖   2
 裤子   2
 九分裤         2
 汉服   2
 豆豆鞋         2
 洞洞鞋         2
 打底衫         2
 刺绣   2
 一字扣带       1
 丝光棉         1
 室外   1
 裙子   1
 男装   1
 护士鞋         1
 蝴蝶结         1
~~~

shell 脚本如下

1. 先输出每一行
2. 对每一行里不需要的 单引号 中括号 小括号 替换
3. 替换后的结果 按照 , 分割成多列 过滤掉 数字列(行转列)
4. 用一个map统计每个词 也就是每一列 出现的次数

> cat qp_pos.txt |tr -s  "[\'\(\)]+" " "|awk -F "," '{for(i=1;i<=NF;i++){if ($i !~ /[0-9]+/){print $i}}}'|awk '{c[$0]++}END{for (i in c) print i"\t" c[i]}'|sort -n -k 2 -r


