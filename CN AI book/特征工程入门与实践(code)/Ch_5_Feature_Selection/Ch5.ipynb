{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Ch5.ipynb","version":"0.3.2","views":{},"default_view":{},"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"metadata":{"id":"l5OaezQWKuX9","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# 导入网格搜索模块\n","from sklearn.model_selection import GridSearchCV\n","\n","\n","def get_best_model_and_accuracy(model, params, X, y):\n","    grid = GridSearchCV(model, # 要搜索的模型\n","                        params, # 要尝试的参数\n","                        error_score=0.) # 如果报错，结果是0\n","    grid.fit(X, y) # 拟合模型和参数\n","    # 经典的性能指标\n","    print(\"Best Accuracy: {}\".format(grid.best_score_))\n","    # 得到最佳准确率的最佳参数\n","    print(\"Best Parameters: {}\".format(grid.best_params_))\n","    # 拟合的平均时间（秒）\n","    print(\"Average Time to Fit (s): {}\".format(round(grid.cv_results_['mean_fit_time'].mean(), 3)))\n","    # 预测的平均时间（秒）\n","    # 从该指标可以看出模型在真实世界的性能\n","    print(\"Average Time to Score (s): {}\".format(round(grid.cv_results_['mean_score_time'].mean(), 3)))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"dROn-uBWVAqU","colab_type":"text"},"cell_type":"markdown","source":["#### 示例：信用卡逾期数据集\n"]},{"metadata":{"id":"zL4lyaR8U20L","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","\n","# 用随机数种子保证随机数永远一致\n","np.random.seed(123)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"XvdFE2Z6VVEY","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":224},"outputId":"36c9a420-9a3a-4291-d756-4e3724375236","executionInfo":{"status":"ok","timestamp":1529809930895,"user_tz":240,"elapsed":1765,"user":{"displayName":"Bei Ning","photoUrl":"//lh6.googleusercontent.com/-MkDu8lm6Q8A/AAAAAAAAAAI/AAAAAAAAAKU/kSp5LEApHT0/s50-c-k-no/photo.jpg","userId":"104532927764063449706"}}},"cell_type":"code","source":["! wget  https://raw.githubusercontent.com/PacktPublishing/Feature-Engineering-Made-Easy/master/Chapter05/credit_card_default.csv"],"execution_count":4,"outputs":[{"output_type":"stream","text":["--2018-06-24 03:12:10--  https://raw.githubusercontent.com/PacktPublishing/Feature-Engineering-Made-Easy/master/Chapter05/credit_card_default.csv\r\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\r\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 2698313 (2.6M) [text/plain]\n","Saving to: ‘credit_card_default.csv’\n","\n","credit_card_default 100%[===================>]   2.57M  --.-KB/s    in 0.1s    \n","\n","2018-06-24 03:12:10 (25.4 MB/s) - ‘credit_card_default.csv’ saved [2698313/2698313]\n","\n"],"name":"stdout"}]},{"metadata":{"id":"T1eJONszVX2Q","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# archive.ics.uci.edu/ml/datasets/default+of+credit+card+clients\n","# 导入数据集\n","credit_card_default = pd.read_csv('../credit_card_default.csv')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"_5tIF35tV73p","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":34},"outputId":"1dcac251-6de7-462b-e3f5-934590c46375","executionInfo":{"status":"ok","timestamp":1529812799261,"user_tz":240,"elapsed":372,"user":{"displayName":"Bei Ning","photoUrl":"//lh6.googleusercontent.com/-MkDu8lm6Q8A/AAAAAAAAAAI/AAAAAAAAAKU/kSp5LEApHT0/s50-c-k-no/photo.jpg","userId":"104532927764063449706"}}},"cell_type":"code","source":["# 30 000行，24列\n","credit_card_default.shape "],"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(30000, 24)"]},"metadata":{"tags":[]},"execution_count":12}]},{"metadata":{"id":"oRihBXFdWbew","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":847},"outputId":"db7156bf-5f28-4052-fd98-0c0d4b3c7af0","executionInfo":{"status":"ok","timestamp":1529812801487,"user_tz":240,"elapsed":308,"user":{"displayName":"Bei Ning","photoUrl":"//lh6.googleusercontent.com/-MkDu8lm6Q8A/AAAAAAAAAAI/AAAAAAAAAKU/kSp5LEApHT0/s50-c-k-no/photo.jpg","userId":"104532927764063449706"}}},"cell_type":"code","source":["# 描述性统计\n","# 调用.T方法进行转置，以便更好地观察\n","credit_card_default.describe().T"],"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>count</th>\n","      <th>mean</th>\n","      <th>std</th>\n","      <th>min</th>\n","      <th>25%</th>\n","      <th>50%</th>\n","      <th>75%</th>\n","      <th>max</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>LIMIT_BAL</th>\n","      <td>30000.0</td>\n","      <td>167484.322667</td>\n","      <td>129747.661567</td>\n","      <td>10000.0</td>\n","      <td>50000.00</td>\n","      <td>140000.0</td>\n","      <td>240000.00</td>\n","      <td>1000000.0</td>\n","    </tr>\n","    <tr>\n","      <th>SEX</th>\n","      <td>30000.0</td>\n","      <td>1.603733</td>\n","      <td>0.489129</td>\n","      <td>1.0</td>\n","      <td>1.00</td>\n","      <td>2.0</td>\n","      <td>2.00</td>\n","      <td>2.0</td>\n","    </tr>\n","    <tr>\n","      <th>EDUCATION</th>\n","      <td>30000.0</td>\n","      <td>1.853133</td>\n","      <td>0.790349</td>\n","      <td>0.0</td>\n","      <td>1.00</td>\n","      <td>2.0</td>\n","      <td>2.00</td>\n","      <td>6.0</td>\n","    </tr>\n","    <tr>\n","      <th>MARRIAGE</th>\n","      <td>30000.0</td>\n","      <td>1.551867</td>\n","      <td>0.521970</td>\n","      <td>0.0</td>\n","      <td>1.00</td>\n","      <td>2.0</td>\n","      <td>2.00</td>\n","      <td>3.0</td>\n","    </tr>\n","    <tr>\n","      <th>AGE</th>\n","      <td>30000.0</td>\n","      <td>35.485500</td>\n","      <td>9.217904</td>\n","      <td>21.0</td>\n","      <td>28.00</td>\n","      <td>34.0</td>\n","      <td>41.00</td>\n","      <td>79.0</td>\n","    </tr>\n","    <tr>\n","      <th>PAY_0</th>\n","      <td>30000.0</td>\n","      <td>-0.016700</td>\n","      <td>1.123802</td>\n","      <td>-2.0</td>\n","      <td>-1.00</td>\n","      <td>0.0</td>\n","      <td>0.00</td>\n","      <td>8.0</td>\n","    </tr>\n","    <tr>\n","      <th>PAY_2</th>\n","      <td>30000.0</td>\n","      <td>-0.133767</td>\n","      <td>1.197186</td>\n","      <td>-2.0</td>\n","      <td>-1.00</td>\n","      <td>0.0</td>\n","      <td>0.00</td>\n","      <td>8.0</td>\n","    </tr>\n","    <tr>\n","      <th>PAY_3</th>\n","      <td>30000.0</td>\n","      <td>-0.166200</td>\n","      <td>1.196868</td>\n","      <td>-2.0</td>\n","      <td>-1.00</td>\n","      <td>0.0</td>\n","      <td>0.00</td>\n","      <td>8.0</td>\n","    </tr>\n","    <tr>\n","      <th>PAY_4</th>\n","      <td>30000.0</td>\n","      <td>-0.220667</td>\n","      <td>1.169139</td>\n","      <td>-2.0</td>\n","      <td>-1.00</td>\n","      <td>0.0</td>\n","      <td>0.00</td>\n","      <td>8.0</td>\n","    </tr>\n","    <tr>\n","      <th>PAY_5</th>\n","      <td>30000.0</td>\n","      <td>-0.266200</td>\n","      <td>1.133187</td>\n","      <td>-2.0</td>\n","      <td>-1.00</td>\n","      <td>0.0</td>\n","      <td>0.00</td>\n","      <td>8.0</td>\n","    </tr>\n","    <tr>\n","      <th>PAY_6</th>\n","      <td>30000.0</td>\n","      <td>-0.291100</td>\n","      <td>1.149988</td>\n","      <td>-2.0</td>\n","      <td>-1.00</td>\n","      <td>0.0</td>\n","      <td>0.00</td>\n","      <td>8.0</td>\n","    </tr>\n","    <tr>\n","      <th>BILL_AMT1</th>\n","      <td>30000.0</td>\n","      <td>51223.330900</td>\n","      <td>73635.860576</td>\n","      <td>-165580.0</td>\n","      <td>3558.75</td>\n","      <td>22381.5</td>\n","      <td>67091.00</td>\n","      <td>964511.0</td>\n","    </tr>\n","    <tr>\n","      <th>BILL_AMT2</th>\n","      <td>30000.0</td>\n","      <td>49179.075167</td>\n","      <td>71173.768783</td>\n","      <td>-69777.0</td>\n","      <td>2984.75</td>\n","      <td>21200.0</td>\n","      <td>64006.25</td>\n","      <td>983931.0</td>\n","    </tr>\n","    <tr>\n","      <th>BILL_AMT3</th>\n","      <td>30000.0</td>\n","      <td>47013.154800</td>\n","      <td>69349.387427</td>\n","      <td>-157264.0</td>\n","      <td>2666.25</td>\n","      <td>20088.5</td>\n","      <td>60164.75</td>\n","      <td>1664089.0</td>\n","    </tr>\n","    <tr>\n","      <th>BILL_AMT4</th>\n","      <td>30000.0</td>\n","      <td>43262.948967</td>\n","      <td>64332.856134</td>\n","      <td>-170000.0</td>\n","      <td>2326.75</td>\n","      <td>19052.0</td>\n","      <td>54506.00</td>\n","      <td>891586.0</td>\n","    </tr>\n","    <tr>\n","      <th>BILL_AMT5</th>\n","      <td>30000.0</td>\n","      <td>40311.400967</td>\n","      <td>60797.155770</td>\n","      <td>-81334.0</td>\n","      <td>1763.00</td>\n","      <td>18104.5</td>\n","      <td>50190.50</td>\n","      <td>927171.0</td>\n","    </tr>\n","    <tr>\n","      <th>BILL_AMT6</th>\n","      <td>30000.0</td>\n","      <td>38871.760400</td>\n","      <td>59554.107537</td>\n","      <td>-339603.0</td>\n","      <td>1256.00</td>\n","      <td>17071.0</td>\n","      <td>49198.25</td>\n","      <td>961664.0</td>\n","    </tr>\n","    <tr>\n","      <th>PAY_AMT1</th>\n","      <td>30000.0</td>\n","      <td>5663.580500</td>\n","      <td>16563.280354</td>\n","      <td>0.0</td>\n","      <td>1000.00</td>\n","      <td>2100.0</td>\n","      <td>5006.00</td>\n","      <td>873552.0</td>\n","    </tr>\n","    <tr>\n","      <th>PAY_AMT2</th>\n","      <td>30000.0</td>\n","      <td>5921.163500</td>\n","      <td>23040.870402</td>\n","      <td>0.0</td>\n","      <td>833.00</td>\n","      <td>2009.0</td>\n","      <td>5000.00</td>\n","      <td>1684259.0</td>\n","    </tr>\n","    <tr>\n","      <th>PAY_AMT3</th>\n","      <td>30000.0</td>\n","      <td>5225.681500</td>\n","      <td>17606.961470</td>\n","      <td>0.0</td>\n","      <td>390.00</td>\n","      <td>1800.0</td>\n","      <td>4505.00</td>\n","      <td>896040.0</td>\n","    </tr>\n","    <tr>\n","      <th>PAY_AMT4</th>\n","      <td>30000.0</td>\n","      <td>4826.076867</td>\n","      <td>15666.159744</td>\n","      <td>0.0</td>\n","      <td>296.00</td>\n","      <td>1500.0</td>\n","      <td>4013.25</td>\n","      <td>621000.0</td>\n","    </tr>\n","    <tr>\n","      <th>PAY_AMT5</th>\n","      <td>30000.0</td>\n","      <td>4799.387633</td>\n","      <td>15278.305679</td>\n","      <td>0.0</td>\n","      <td>252.50</td>\n","      <td>1500.0</td>\n","      <td>4031.50</td>\n","      <td>426529.0</td>\n","    </tr>\n","    <tr>\n","      <th>PAY_AMT6</th>\n","      <td>30000.0</td>\n","      <td>5215.502567</td>\n","      <td>17777.465775</td>\n","      <td>0.0</td>\n","      <td>117.75</td>\n","      <td>1500.0</td>\n","      <td>4000.00</td>\n","      <td>528666.0</td>\n","    </tr>\n","    <tr>\n","      <th>default payment next month</th>\n","      <td>30000.0</td>\n","      <td>0.221200</td>\n","      <td>0.415062</td>\n","      <td>0.0</td>\n","      <td>0.00</td>\n","      <td>0.0</td>\n","      <td>0.00</td>\n","      <td>1.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                              count           mean            std       min  \\\n","LIMIT_BAL                   30000.0  167484.322667  129747.661567   10000.0   \n","SEX                         30000.0       1.603733       0.489129       1.0   \n","EDUCATION                   30000.0       1.853133       0.790349       0.0   \n","MARRIAGE                    30000.0       1.551867       0.521970       0.0   \n","AGE                         30000.0      35.485500       9.217904      21.0   \n","PAY_0                       30000.0      -0.016700       1.123802      -2.0   \n","PAY_2                       30000.0      -0.133767       1.197186      -2.0   \n","PAY_3                       30000.0      -0.166200       1.196868      -2.0   \n","PAY_4                       30000.0      -0.220667       1.169139      -2.0   \n","PAY_5                       30000.0      -0.266200       1.133187      -2.0   \n","PAY_6                       30000.0      -0.291100       1.149988      -2.0   \n","BILL_AMT1                   30000.0   51223.330900   73635.860576 -165580.0   \n","BILL_AMT2                   30000.0   49179.075167   71173.768783  -69777.0   \n","BILL_AMT3                   30000.0   47013.154800   69349.387427 -157264.0   \n","BILL_AMT4                   30000.0   43262.948967   64332.856134 -170000.0   \n","BILL_AMT5                   30000.0   40311.400967   60797.155770  -81334.0   \n","BILL_AMT6                   30000.0   38871.760400   59554.107537 -339603.0   \n","PAY_AMT1                    30000.0    5663.580500   16563.280354       0.0   \n","PAY_AMT2                    30000.0    5921.163500   23040.870402       0.0   \n","PAY_AMT3                    30000.0    5225.681500   17606.961470       0.0   \n","PAY_AMT4                    30000.0    4826.076867   15666.159744       0.0   \n","PAY_AMT5                    30000.0    4799.387633   15278.305679       0.0   \n","PAY_AMT6                    30000.0    5215.502567   17777.465775       0.0   \n","default payment next month  30000.0       0.221200       0.415062       0.0   \n","\n","                                 25%       50%        75%        max  \n","LIMIT_BAL                   50000.00  140000.0  240000.00  1000000.0  \n","SEX                             1.00       2.0       2.00        2.0  \n","EDUCATION                       1.00       2.0       2.00        6.0  \n","MARRIAGE                        1.00       2.0       2.00        3.0  \n","AGE                            28.00      34.0      41.00       79.0  \n","PAY_0                          -1.00       0.0       0.00        8.0  \n","PAY_2                          -1.00       0.0       0.00        8.0  \n","PAY_3                          -1.00       0.0       0.00        8.0  \n","PAY_4                          -1.00       0.0       0.00        8.0  \n","PAY_5                          -1.00       0.0       0.00        8.0  \n","PAY_6                          -1.00       0.0       0.00        8.0  \n","BILL_AMT1                    3558.75   22381.5   67091.00   964511.0  \n","BILL_AMT2                    2984.75   21200.0   64006.25   983931.0  \n","BILL_AMT3                    2666.25   20088.5   60164.75  1664089.0  \n","BILL_AMT4                    2326.75   19052.0   54506.00   891586.0  \n","BILL_AMT5                    1763.00   18104.5   50190.50   927171.0  \n","BILL_AMT6                    1256.00   17071.0   49198.25   961664.0  \n","PAY_AMT1                     1000.00    2100.0    5006.00   873552.0  \n","PAY_AMT2                      833.00    2009.0    5000.00  1684259.0  \n","PAY_AMT3                      390.00    1800.0    4505.00   896040.0  \n","PAY_AMT4                      296.00    1500.0    4013.25   621000.0  \n","PAY_AMT5                      252.50    1500.0    4031.50   426529.0  \n","PAY_AMT6                      117.75    1500.0    4000.00   528666.0  \n","default payment next month      0.00       0.0       0.00        1.0  "]},"metadata":{"tags":[]},"execution_count":13}]},{"metadata":{"id":"l12oWvC7XyX9","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":442},"outputId":"88499c04-7c3a-4c07-d899-326259cd72c3","executionInfo":{"status":"ok","timestamp":1529812804963,"user_tz":240,"elapsed":458,"user":{"displayName":"Bei Ning","photoUrl":"//lh6.googleusercontent.com/-MkDu8lm6Q8A/AAAAAAAAAAI/AAAAAAAAAKU/kSp5LEApHT0/s50-c-k-no/photo.jpg","userId":"104532927764063449706"}}},"cell_type":"code","source":["# 检查缺失值，本数据集中不存在\n","credit_card_default.isnull().sum()"],"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["LIMIT_BAL                     0\n","SEX                           0\n","EDUCATION                     0\n","MARRIAGE                      0\n","AGE                           0\n","PAY_0                         0\n","PAY_2                         0\n","PAY_3                         0\n","PAY_4                         0\n","PAY_5                         0\n","PAY_6                         0\n","BILL_AMT1                     0\n","BILL_AMT2                     0\n","BILL_AMT3                     0\n","BILL_AMT4                     0\n","BILL_AMT5                     0\n","BILL_AMT6                     0\n","PAY_AMT1                      0\n","PAY_AMT2                      0\n","PAY_AMT3                      0\n","PAY_AMT4                      0\n","PAY_AMT5                      0\n","PAY_AMT6                      0\n","default payment next month    0\n","dtype: int64"]},"metadata":{"tags":[]},"execution_count":14}]},{"metadata":{"id":"yeQ3kfbyYCR6","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# 特征矩阵\n","X = credit_card_default.drop('default payment next month', axis=1)\n","\n","# 响应变量\n","y = credit_card_default['default payment next month']"],"execution_count":0,"outputs":[]},{"metadata":{"id":"cAyuqARRYhEL","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":68},"outputId":"71fdd700-55f0-4a20-a88a-239c512ef4a4","executionInfo":{"status":"ok","timestamp":1529467778745,"user_tz":240,"elapsed":312,"user":{"displayName":"Bei Ning","photoUrl":"//lh6.googleusercontent.com/-MkDu8lm6Q8A/AAAAAAAAAAI/AAAAAAAAAKU/kSp5LEApHT0/s50-c-k-no/photo.jpg","userId":"104532927764063449706"}}},"cell_type":"code","source":["# 取空准确率\n","y.value_counts(normalize=True)"],"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0    0.7788\n","1    0.2212\n","Name: default payment next month, dtype: float64"]},"metadata":{"tags":[]},"execution_count":10}]},{"metadata":{"id":"tMdBmhvWch3j","colab_type":"text"},"cell_type":"markdown","source":["### 创建基准机器学习流水线\n"]},{"metadata":{"id":"LiIHKLdNckBC","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# 导入4种模型\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.ensemble import RandomForestClassifier"],"execution_count":0,"outputs":[]},{"metadata":{"id":"ZtCh-3vuc8fb","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# 为网格搜索设置变量\n","# 先设置机器学习模型的参数\n","\n","# 逻辑回归\n","lr_params = {'C':[1e-1, 1e0, 1e1, 1e2], 'penalty':['l1', 'l2']}\n","\n","# KNN\n","knn_params = {'n_neighbors': [1, 3, 5, 7]}\n","\n","# 决策树\n","tree_params = {'max_depth':[None, 1, 3, 5, 7]}\n","\n","# 随机森林\n","forest_params = {'n_estimators': [10, 50, 100], 'max_depth': [None, 1, 3, 5, 7]}"],"execution_count":0,"outputs":[]},{"metadata":{"id":"iCCysNYMdahH","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# 实例化机器学习模型\n","lr = LogisticRegression()\n","knn = KNeighborsClassifier()\n","d_tree = DecisionTreeClassifier()\n","forest = RandomForestClassifier()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"94UnwuZUdvnQ","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":85},"outputId":"2a9fc7b4-7510-48d5-e784-baff97e40dac","executionInfo":{"status":"ok","timestamp":1529469158187,"user_tz":240,"elapsed":16648,"user":{"displayName":"Bei Ning","photoUrl":"//lh6.googleusercontent.com/-MkDu8lm6Q8A/AAAAAAAAAAI/AAAAAAAAAKU/kSp5LEApHT0/s50-c-k-no/photo.jpg","userId":"104532927764063449706"}}},"cell_type":"code","source":["get_best_model_and_accuracy(lr, lr_params, X, y)"],"execution_count":14,"outputs":[{"output_type":"stream","text":["Best Accuracy: 0.8095333333333333\n","Best Parameters: {'C': 0.1, 'penalty': 'l1'}\n","Average Time to Fit (s): 0.643\n","Average Time to Score (s): 0.003\n"],"name":"stdout"}]},{"metadata":{"id":"XYbRyX8SeWNP","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":85},"outputId":"5d6826c7-15cf-4c58-a33f-24a9b1e2eb54","executionInfo":{"status":"ok","timestamp":1529469326656,"user_tz":240,"elapsed":27289,"user":{"displayName":"Bei Ning","photoUrl":"//lh6.googleusercontent.com/-MkDu8lm6Q8A/AAAAAAAAAAI/AAAAAAAAAKU/kSp5LEApHT0/s50-c-k-no/photo.jpg","userId":"104532927764063449706"}}},"cell_type":"code","source":["get_best_model_and_accuracy(knn, knn_params, X, y)"],"execution_count":15,"outputs":[{"output_type":"stream","text":["Best Accuracy: 0.7602333333333333\n","Best Parameters: {'n_neighbors': 7}\n","Average Time to Fit (s): 0.032\n","Average Time to Score (s): 0.862\n"],"name":"stdout"}]},{"metadata":{"id":"9GvU4l-I_Q6t","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# 导入所需的包\n","from sklearn.pipeline import Pipeline\n","from sklearn.preprocessing import StandardScaler"],"execution_count":0,"outputs":[]},{"metadata":{"id":"C2BqOVh9fwA1","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":3231},"outputId":"091fdd01-bc01-487b-d46b-a73b8187ced5","executionInfo":{"status":"error","timestamp":1529813434177,"user_tz":240,"elapsed":36303,"user":{"displayName":"Bei Ning","photoUrl":"//lh6.googleusercontent.com/-MkDu8lm6Q8A/AAAAAAAAAAI/AAAAAAAAAKU/kSp5LEApHT0/s50-c-k-no/photo.jpg","userId":"104532927764063449706"}}},"cell_type":"code","source":["\n","\n","# 为流水线设置KNN参数\n","knn_pipe_params = {'classifier__{}'.format(k): v for k, v in knn_params.items()}\n","\n","# KNN 需要标准化的参数\n","knn_pipe = Pipeline([('scale', StandardScaler()), ('classifier', knn)])\n","\n","# 拟合快，预测慢\n","get_best_model_and_accuracy(knn_pipe, knn_pipe_params, X, y)\n","\n","print(knn_pipe_params)  # {'classifier__n_neighbors': [1, 3, 5, 7]} "],"execution_count":29,"outputs":[{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-29-889a99ea92be>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# 拟合快 预测慢\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mget_best_model_and_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mknn_pipe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mknn_pipe_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mknn_pipe_params\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# {'classifier__n_neighbors': [1, 3, 5, 7]}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-1-31398e513021>\u001b[0m in \u001b[0;36mget_best_model_and_accuracy\u001b[0;34m(model, params, X, y)\u001b[0m\n\u001b[1;32m      6\u001b[0m                         \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# 要搜索的参数\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m                         error_score=0.) # 如果报错 结果是0\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 拟合模型和参数\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;31m# 经典的精度\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Best Accuracy: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    637\u001b[0m                                   error_score=self.error_score)\n\u001b[1;32m    638\u001b[0m           for parameters, (train, test) in product(candidate_params,\n\u001b[0;32m--> 639\u001b[0;31m                                                    cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m         \u001b[0;31m# if one choose to see train score, \"out\" will contain train score info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    777\u001b[0m             \u001b[0;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    623\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 625\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    586\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0mcb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 588\u001b[0;31m         \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    589\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, error_score)\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             train_scores = _score(estimator, X_train, y_train, scorer,\n\u001b[0;32m--> 492\u001b[0;31m                                   is_multimetric)\n\u001b[0m\u001b[1;32m    493\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_score\u001b[0;34m(estimator, X_test, y_test, scorer, is_multimetric)\u001b[0m\n\u001b[1;32m    521\u001b[0m     \"\"\"\n\u001b[1;32m    522\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_multimetric\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 523\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_multimetric_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    524\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_multimetric_score\u001b[0;34m(estimator, X_test, y_test, scorers)\u001b[0m\n\u001b[1;32m    551\u001b[0m             \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 553\u001b[0;31m             \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'item'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/scorer.py\u001b[0m in \u001b[0;36m_passthrough_scorer\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_passthrough_scorer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m     \u001b[0;34m\"\"\"Function that wraps estimator.score\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/utils/metaestimators.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;31m# lambda, but not partial, allows help() to work with update_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m         \u001b[0;31m# update the docstring of the returned function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0mupdate_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mscore\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mscore_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sample_weight'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 490\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mscore_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    491\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mscore\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    347\u001b[0m         \"\"\"\n\u001b[1;32m    348\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 349\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/neighbors/classification.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m         \u001b[0mneigh_dist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneigh_ind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkneighbors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/neighbors/base.py\u001b[0m in \u001b[0;36mkneighbors\u001b[0;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[1;32m    383\u001b[0m                 delayed(self._tree.query, check_pickle=False)(\n\u001b[1;32m    384\u001b[0m                     X[s], n_neighbors, return_distance)\n\u001b[0;32m--> 385\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgen_even_slices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m             )\n\u001b[1;32m    387\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mreturn_distance\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    777\u001b[0m             \u001b[0;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    623\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 625\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    586\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0mcb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 588\u001b[0;31m         \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    589\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"metadata":{"id":"FqsAf93lgfVk","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":85},"outputId":"2207cbe9-d769-4b8a-e2e4-cbf26061861c","executionInfo":{"status":"ok","timestamp":1529469994104,"user_tz":240,"elapsed":3381,"user":{"displayName":"Bei Ning","photoUrl":"//lh6.googleusercontent.com/-MkDu8lm6Q8A/AAAAAAAAAAI/AAAAAAAAAKU/kSp5LEApHT0/s50-c-k-no/photo.jpg","userId":"104532927764063449706"}}},"cell_type":"code","source":["get_best_model_and_accuracy(d_tree, tree_params, X, y)"],"execution_count":18,"outputs":[{"output_type":"stream","text":["Best Accuracy: 0.8202666666666667\n","Best Parameters: {'max_depth': 3}\n","Average Time to Fit (s): 0.183\n","Average Time to Score (s): 0.003\n"],"name":"stdout"}]},{"metadata":{"id":"P5l9Gf-mg2sl","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":85},"outputId":"fadd7267-3f80-4c42-ca71-3f2b4c05d2db","executionInfo":{"status":"ok","timestamp":1529470065567,"user_tz":240,"elapsed":69373,"user":{"displayName":"Bei Ning","photoUrl":"//lh6.googleusercontent.com/-MkDu8lm6Q8A/AAAAAAAAAAI/AAAAAAAAAKU/kSp5LEApHT0/s50-c-k-no/photo.jpg","userId":"104532927764063449706"}}},"cell_type":"code","source":["get_best_model_and_accuracy(forest, forest_params, X, y)"],"execution_count":19,"outputs":[{"output_type":"stream","text":["Best Accuracy: 0.8195666666666667\n","Best Parameters: {'max_depth': 7, 'n_estimators': 50}\n","Average Time to Fit (s): 1.329\n","Average Time to Score (s): 0.054\n"],"name":"stdout"}]},{"metadata":{"id":"Y_kK0SejqMCe","colab_type":"text"},"cell_type":"markdown","source":["##### 使用相关系数\n"]},{"metadata":{"id":"ZBptctg2qLFx","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":927},"outputId":"cec3dd6d-06b4-451a-8463-c978f9f449bc","executionInfo":{"status":"ok","timestamp":1529472417057,"user_tz":240,"elapsed":350,"user":{"displayName":"Bei Ning","photoUrl":"//lh6.googleusercontent.com/-MkDu8lm6Q8A/AAAAAAAAAAI/AAAAAAAAAKU/kSp5LEApHT0/s50-c-k-no/photo.jpg","userId":"104532927764063449706"}}},"cell_type":"code","source":["credit_card_default.corr()"],"execution_count":20,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>LIMIT_BAL</th>\n","      <th>SEX</th>\n","      <th>EDUCATION</th>\n","      <th>MARRIAGE</th>\n","      <th>AGE</th>\n","      <th>PAY_0</th>\n","      <th>PAY_2</th>\n","      <th>PAY_3</th>\n","      <th>PAY_4</th>\n","      <th>PAY_5</th>\n","      <th>...</th>\n","      <th>BILL_AMT4</th>\n","      <th>BILL_AMT5</th>\n","      <th>BILL_AMT6</th>\n","      <th>PAY_AMT1</th>\n","      <th>PAY_AMT2</th>\n","      <th>PAY_AMT3</th>\n","      <th>PAY_AMT4</th>\n","      <th>PAY_AMT5</th>\n","      <th>PAY_AMT6</th>\n","      <th>default payment next month</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>LIMIT_BAL</th>\n","      <td>1.000000</td>\n","      <td>0.024755</td>\n","      <td>-0.219161</td>\n","      <td>-0.108139</td>\n","      <td>0.144713</td>\n","      <td>-0.271214</td>\n","      <td>-0.296382</td>\n","      <td>-0.286123</td>\n","      <td>-0.267460</td>\n","      <td>-0.249411</td>\n","      <td>...</td>\n","      <td>0.293988</td>\n","      <td>0.295562</td>\n","      <td>0.290389</td>\n","      <td>0.195236</td>\n","      <td>0.178408</td>\n","      <td>0.210167</td>\n","      <td>0.203242</td>\n","      <td>0.217202</td>\n","      <td>0.219595</td>\n","      <td>-0.153520</td>\n","    </tr>\n","    <tr>\n","      <th>SEX</th>\n","      <td>0.024755</td>\n","      <td>1.000000</td>\n","      <td>0.014232</td>\n","      <td>-0.031389</td>\n","      <td>-0.090874</td>\n","      <td>-0.057643</td>\n","      <td>-0.070771</td>\n","      <td>-0.066096</td>\n","      <td>-0.060173</td>\n","      <td>-0.055064</td>\n","      <td>...</td>\n","      <td>-0.021880</td>\n","      <td>-0.017005</td>\n","      <td>-0.016733</td>\n","      <td>-0.000242</td>\n","      <td>-0.001391</td>\n","      <td>-0.008597</td>\n","      <td>-0.002229</td>\n","      <td>-0.001667</td>\n","      <td>-0.002766</td>\n","      <td>-0.039961</td>\n","    </tr>\n","    <tr>\n","      <th>EDUCATION</th>\n","      <td>-0.219161</td>\n","      <td>0.014232</td>\n","      <td>1.000000</td>\n","      <td>-0.143464</td>\n","      <td>0.175061</td>\n","      <td>0.105364</td>\n","      <td>0.121566</td>\n","      <td>0.114025</td>\n","      <td>0.108793</td>\n","      <td>0.097520</td>\n","      <td>...</td>\n","      <td>-0.000451</td>\n","      <td>-0.007567</td>\n","      <td>-0.009099</td>\n","      <td>-0.037456</td>\n","      <td>-0.030038</td>\n","      <td>-0.039943</td>\n","      <td>-0.038218</td>\n","      <td>-0.040358</td>\n","      <td>-0.037200</td>\n","      <td>0.028006</td>\n","    </tr>\n","    <tr>\n","      <th>MARRIAGE</th>\n","      <td>-0.108139</td>\n","      <td>-0.031389</td>\n","      <td>-0.143464</td>\n","      <td>1.000000</td>\n","      <td>-0.414170</td>\n","      <td>0.019917</td>\n","      <td>0.024199</td>\n","      <td>0.032688</td>\n","      <td>0.033122</td>\n","      <td>0.035629</td>\n","      <td>...</td>\n","      <td>-0.023344</td>\n","      <td>-0.025393</td>\n","      <td>-0.021207</td>\n","      <td>-0.005979</td>\n","      <td>-0.008093</td>\n","      <td>-0.003541</td>\n","      <td>-0.012659</td>\n","      <td>-0.001205</td>\n","      <td>-0.006641</td>\n","      <td>-0.024339</td>\n","    </tr>\n","    <tr>\n","      <th>AGE</th>\n","      <td>0.144713</td>\n","      <td>-0.090874</td>\n","      <td>0.175061</td>\n","      <td>-0.414170</td>\n","      <td>1.000000</td>\n","      <td>-0.039447</td>\n","      <td>-0.050148</td>\n","      <td>-0.053048</td>\n","      <td>-0.049722</td>\n","      <td>-0.053826</td>\n","      <td>...</td>\n","      <td>0.051353</td>\n","      <td>0.049345</td>\n","      <td>0.047613</td>\n","      <td>0.026147</td>\n","      <td>0.021785</td>\n","      <td>0.029247</td>\n","      <td>0.021379</td>\n","      <td>0.022850</td>\n","      <td>0.019478</td>\n","      <td>0.013890</td>\n","    </tr>\n","    <tr>\n","      <th>PAY_0</th>\n","      <td>-0.271214</td>\n","      <td>-0.057643</td>\n","      <td>0.105364</td>\n","      <td>0.019917</td>\n","      <td>-0.039447</td>\n","      <td>1.000000</td>\n","      <td>0.672164</td>\n","      <td>0.574245</td>\n","      <td>0.538841</td>\n","      <td>0.509426</td>\n","      <td>...</td>\n","      <td>0.179125</td>\n","      <td>0.180635</td>\n","      <td>0.176980</td>\n","      <td>-0.079269</td>\n","      <td>-0.070101</td>\n","      <td>-0.070561</td>\n","      <td>-0.064005</td>\n","      <td>-0.058190</td>\n","      <td>-0.058673</td>\n","      <td>0.324794</td>\n","    </tr>\n","    <tr>\n","      <th>PAY_2</th>\n","      <td>-0.296382</td>\n","      <td>-0.070771</td>\n","      <td>0.121566</td>\n","      <td>0.024199</td>\n","      <td>-0.050148</td>\n","      <td>0.672164</td>\n","      <td>1.000000</td>\n","      <td>0.766552</td>\n","      <td>0.662067</td>\n","      <td>0.622780</td>\n","      <td>...</td>\n","      <td>0.222237</td>\n","      <td>0.221348</td>\n","      <td>0.219403</td>\n","      <td>-0.080701</td>\n","      <td>-0.058990</td>\n","      <td>-0.055901</td>\n","      <td>-0.046858</td>\n","      <td>-0.037093</td>\n","      <td>-0.036500</td>\n","      <td>0.263551</td>\n","    </tr>\n","    <tr>\n","      <th>PAY_3</th>\n","      <td>-0.286123</td>\n","      <td>-0.066096</td>\n","      <td>0.114025</td>\n","      <td>0.032688</td>\n","      <td>-0.053048</td>\n","      <td>0.574245</td>\n","      <td>0.766552</td>\n","      <td>1.000000</td>\n","      <td>0.777359</td>\n","      <td>0.686775</td>\n","      <td>...</td>\n","      <td>0.227202</td>\n","      <td>0.225145</td>\n","      <td>0.222327</td>\n","      <td>0.001295</td>\n","      <td>-0.066793</td>\n","      <td>-0.053311</td>\n","      <td>-0.046067</td>\n","      <td>-0.035863</td>\n","      <td>-0.035861</td>\n","      <td>0.235253</td>\n","    </tr>\n","    <tr>\n","      <th>PAY_4</th>\n","      <td>-0.267460</td>\n","      <td>-0.060173</td>\n","      <td>0.108793</td>\n","      <td>0.033122</td>\n","      <td>-0.049722</td>\n","      <td>0.538841</td>\n","      <td>0.662067</td>\n","      <td>0.777359</td>\n","      <td>1.000000</td>\n","      <td>0.819835</td>\n","      <td>...</td>\n","      <td>0.245917</td>\n","      <td>0.242902</td>\n","      <td>0.239154</td>\n","      <td>-0.009362</td>\n","      <td>-0.001944</td>\n","      <td>-0.069235</td>\n","      <td>-0.043461</td>\n","      <td>-0.033590</td>\n","      <td>-0.026565</td>\n","      <td>0.216614</td>\n","    </tr>\n","    <tr>\n","      <th>PAY_5</th>\n","      <td>-0.249411</td>\n","      <td>-0.055064</td>\n","      <td>0.097520</td>\n","      <td>0.035629</td>\n","      <td>-0.053826</td>\n","      <td>0.509426</td>\n","      <td>0.622780</td>\n","      <td>0.686775</td>\n","      <td>0.819835</td>\n","      <td>1.000000</td>\n","      <td>...</td>\n","      <td>0.271915</td>\n","      <td>0.269783</td>\n","      <td>0.262509</td>\n","      <td>-0.006089</td>\n","      <td>-0.003191</td>\n","      <td>0.009062</td>\n","      <td>-0.058299</td>\n","      <td>-0.033337</td>\n","      <td>-0.023027</td>\n","      <td>0.204149</td>\n","    </tr>\n","    <tr>\n","      <th>PAY_6</th>\n","      <td>-0.235195</td>\n","      <td>-0.044008</td>\n","      <td>0.082316</td>\n","      <td>0.034345</td>\n","      <td>-0.048773</td>\n","      <td>0.474553</td>\n","      <td>0.575501</td>\n","      <td>0.632684</td>\n","      <td>0.716449</td>\n","      <td>0.816900</td>\n","      <td>...</td>\n","      <td>0.266356</td>\n","      <td>0.290894</td>\n","      <td>0.285091</td>\n","      <td>-0.001496</td>\n","      <td>-0.005223</td>\n","      <td>0.005834</td>\n","      <td>0.019018</td>\n","      <td>-0.046434</td>\n","      <td>-0.025299</td>\n","      <td>0.186866</td>\n","    </tr>\n","    <tr>\n","      <th>BILL_AMT1</th>\n","      <td>0.285430</td>\n","      <td>-0.033642</td>\n","      <td>0.023581</td>\n","      <td>-0.023472</td>\n","      <td>0.056239</td>\n","      <td>0.187068</td>\n","      <td>0.234887</td>\n","      <td>0.208473</td>\n","      <td>0.202812</td>\n","      <td>0.206684</td>\n","      <td>...</td>\n","      <td>0.860272</td>\n","      <td>0.829779</td>\n","      <td>0.802650</td>\n","      <td>0.140277</td>\n","      <td>0.099355</td>\n","      <td>0.156887</td>\n","      <td>0.158303</td>\n","      <td>0.167026</td>\n","      <td>0.179341</td>\n","      <td>-0.019644</td>\n","    </tr>\n","    <tr>\n","      <th>BILL_AMT2</th>\n","      <td>0.278314</td>\n","      <td>-0.031183</td>\n","      <td>0.018749</td>\n","      <td>-0.021602</td>\n","      <td>0.054283</td>\n","      <td>0.189859</td>\n","      <td>0.235257</td>\n","      <td>0.237295</td>\n","      <td>0.225816</td>\n","      <td>0.226913</td>\n","      <td>...</td>\n","      <td>0.892482</td>\n","      <td>0.859778</td>\n","      <td>0.831594</td>\n","      <td>0.280365</td>\n","      <td>0.100851</td>\n","      <td>0.150718</td>\n","      <td>0.147398</td>\n","      <td>0.157957</td>\n","      <td>0.174256</td>\n","      <td>-0.014193</td>\n","    </tr>\n","    <tr>\n","      <th>BILL_AMT3</th>\n","      <td>0.283236</td>\n","      <td>-0.024563</td>\n","      <td>0.013002</td>\n","      <td>-0.024909</td>\n","      <td>0.053710</td>\n","      <td>0.179785</td>\n","      <td>0.224146</td>\n","      <td>0.227494</td>\n","      <td>0.244983</td>\n","      <td>0.243335</td>\n","      <td>...</td>\n","      <td>0.923969</td>\n","      <td>0.883910</td>\n","      <td>0.853320</td>\n","      <td>0.244335</td>\n","      <td>0.316936</td>\n","      <td>0.130011</td>\n","      <td>0.143405</td>\n","      <td>0.179712</td>\n","      <td>0.182326</td>\n","      <td>-0.014076</td>\n","    </tr>\n","    <tr>\n","      <th>BILL_AMT4</th>\n","      <td>0.293988</td>\n","      <td>-0.021880</td>\n","      <td>-0.000451</td>\n","      <td>-0.023344</td>\n","      <td>0.051353</td>\n","      <td>0.179125</td>\n","      <td>0.222237</td>\n","      <td>0.227202</td>\n","      <td>0.245917</td>\n","      <td>0.271915</td>\n","      <td>...</td>\n","      <td>1.000000</td>\n","      <td>0.940134</td>\n","      <td>0.900941</td>\n","      <td>0.233012</td>\n","      <td>0.207564</td>\n","      <td>0.300023</td>\n","      <td>0.130191</td>\n","      <td>0.160433</td>\n","      <td>0.177637</td>\n","      <td>-0.010156</td>\n","    </tr>\n","    <tr>\n","      <th>BILL_AMT5</th>\n","      <td>0.295562</td>\n","      <td>-0.017005</td>\n","      <td>-0.007567</td>\n","      <td>-0.025393</td>\n","      <td>0.049345</td>\n","      <td>0.180635</td>\n","      <td>0.221348</td>\n","      <td>0.225145</td>\n","      <td>0.242902</td>\n","      <td>0.269783</td>\n","      <td>...</td>\n","      <td>0.940134</td>\n","      <td>1.000000</td>\n","      <td>0.946197</td>\n","      <td>0.217031</td>\n","      <td>0.181246</td>\n","      <td>0.252305</td>\n","      <td>0.293118</td>\n","      <td>0.141574</td>\n","      <td>0.164184</td>\n","      <td>-0.006760</td>\n","    </tr>\n","    <tr>\n","      <th>BILL_AMT6</th>\n","      <td>0.290389</td>\n","      <td>-0.016733</td>\n","      <td>-0.009099</td>\n","      <td>-0.021207</td>\n","      <td>0.047613</td>\n","      <td>0.176980</td>\n","      <td>0.219403</td>\n","      <td>0.222327</td>\n","      <td>0.239154</td>\n","      <td>0.262509</td>\n","      <td>...</td>\n","      <td>0.900941</td>\n","      <td>0.946197</td>\n","      <td>1.000000</td>\n","      <td>0.199965</td>\n","      <td>0.172663</td>\n","      <td>0.233770</td>\n","      <td>0.250237</td>\n","      <td>0.307729</td>\n","      <td>0.115494</td>\n","      <td>-0.005372</td>\n","    </tr>\n","    <tr>\n","      <th>PAY_AMT1</th>\n","      <td>0.195236</td>\n","      <td>-0.000242</td>\n","      <td>-0.037456</td>\n","      <td>-0.005979</td>\n","      <td>0.026147</td>\n","      <td>-0.079269</td>\n","      <td>-0.080701</td>\n","      <td>0.001295</td>\n","      <td>-0.009362</td>\n","      <td>-0.006089</td>\n","      <td>...</td>\n","      <td>0.233012</td>\n","      <td>0.217031</td>\n","      <td>0.199965</td>\n","      <td>1.000000</td>\n","      <td>0.285576</td>\n","      <td>0.252191</td>\n","      <td>0.199558</td>\n","      <td>0.148459</td>\n","      <td>0.185735</td>\n","      <td>-0.072929</td>\n","    </tr>\n","    <tr>\n","      <th>PAY_AMT2</th>\n","      <td>0.178408</td>\n","      <td>-0.001391</td>\n","      <td>-0.030038</td>\n","      <td>-0.008093</td>\n","      <td>0.021785</td>\n","      <td>-0.070101</td>\n","      <td>-0.058990</td>\n","      <td>-0.066793</td>\n","      <td>-0.001944</td>\n","      <td>-0.003191</td>\n","      <td>...</td>\n","      <td>0.207564</td>\n","      <td>0.181246</td>\n","      <td>0.172663</td>\n","      <td>0.285576</td>\n","      <td>1.000000</td>\n","      <td>0.244770</td>\n","      <td>0.180107</td>\n","      <td>0.180908</td>\n","      <td>0.157634</td>\n","      <td>-0.058579</td>\n","    </tr>\n","    <tr>\n","      <th>PAY_AMT3</th>\n","      <td>0.210167</td>\n","      <td>-0.008597</td>\n","      <td>-0.039943</td>\n","      <td>-0.003541</td>\n","      <td>0.029247</td>\n","      <td>-0.070561</td>\n","      <td>-0.055901</td>\n","      <td>-0.053311</td>\n","      <td>-0.069235</td>\n","      <td>0.009062</td>\n","      <td>...</td>\n","      <td>0.300023</td>\n","      <td>0.252305</td>\n","      <td>0.233770</td>\n","      <td>0.252191</td>\n","      <td>0.244770</td>\n","      <td>1.000000</td>\n","      <td>0.216325</td>\n","      <td>0.159214</td>\n","      <td>0.162740</td>\n","      <td>-0.056250</td>\n","    </tr>\n","    <tr>\n","      <th>PAY_AMT4</th>\n","      <td>0.203242</td>\n","      <td>-0.002229</td>\n","      <td>-0.038218</td>\n","      <td>-0.012659</td>\n","      <td>0.021379</td>\n","      <td>-0.064005</td>\n","      <td>-0.046858</td>\n","      <td>-0.046067</td>\n","      <td>-0.043461</td>\n","      <td>-0.058299</td>\n","      <td>...</td>\n","      <td>0.130191</td>\n","      <td>0.293118</td>\n","      <td>0.250237</td>\n","      <td>0.199558</td>\n","      <td>0.180107</td>\n","      <td>0.216325</td>\n","      <td>1.000000</td>\n","      <td>0.151830</td>\n","      <td>0.157834</td>\n","      <td>-0.056827</td>\n","    </tr>\n","    <tr>\n","      <th>PAY_AMT5</th>\n","      <td>0.217202</td>\n","      <td>-0.001667</td>\n","      <td>-0.040358</td>\n","      <td>-0.001205</td>\n","      <td>0.022850</td>\n","      <td>-0.058190</td>\n","      <td>-0.037093</td>\n","      <td>-0.035863</td>\n","      <td>-0.033590</td>\n","      <td>-0.033337</td>\n","      <td>...</td>\n","      <td>0.160433</td>\n","      <td>0.141574</td>\n","      <td>0.307729</td>\n","      <td>0.148459</td>\n","      <td>0.180908</td>\n","      <td>0.159214</td>\n","      <td>0.151830</td>\n","      <td>1.000000</td>\n","      <td>0.154896</td>\n","      <td>-0.055124</td>\n","    </tr>\n","    <tr>\n","      <th>PAY_AMT6</th>\n","      <td>0.219595</td>\n","      <td>-0.002766</td>\n","      <td>-0.037200</td>\n","      <td>-0.006641</td>\n","      <td>0.019478</td>\n","      <td>-0.058673</td>\n","      <td>-0.036500</td>\n","      <td>-0.035861</td>\n","      <td>-0.026565</td>\n","      <td>-0.023027</td>\n","      <td>...</td>\n","      <td>0.177637</td>\n","      <td>0.164184</td>\n","      <td>0.115494</td>\n","      <td>0.185735</td>\n","      <td>0.157634</td>\n","      <td>0.162740</td>\n","      <td>0.157834</td>\n","      <td>0.154896</td>\n","      <td>1.000000</td>\n","      <td>-0.053183</td>\n","    </tr>\n","    <tr>\n","      <th>default payment next month</th>\n","      <td>-0.153520</td>\n","      <td>-0.039961</td>\n","      <td>0.028006</td>\n","      <td>-0.024339</td>\n","      <td>0.013890</td>\n","      <td>0.324794</td>\n","      <td>0.263551</td>\n","      <td>0.235253</td>\n","      <td>0.216614</td>\n","      <td>0.204149</td>\n","      <td>...</td>\n","      <td>-0.010156</td>\n","      <td>-0.006760</td>\n","      <td>-0.005372</td>\n","      <td>-0.072929</td>\n","      <td>-0.058579</td>\n","      <td>-0.056250</td>\n","      <td>-0.056827</td>\n","      <td>-0.055124</td>\n","      <td>-0.053183</td>\n","      <td>1.000000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>24 rows × 24 columns</p>\n","</div>"],"text/plain":["                            LIMIT_BAL       SEX  EDUCATION  MARRIAGE  \\\n","LIMIT_BAL                    1.000000  0.024755  -0.219161 -0.108139   \n","SEX                          0.024755  1.000000   0.014232 -0.031389   \n","EDUCATION                   -0.219161  0.014232   1.000000 -0.143464   \n","MARRIAGE                    -0.108139 -0.031389  -0.143464  1.000000   \n","AGE                          0.144713 -0.090874   0.175061 -0.414170   \n","PAY_0                       -0.271214 -0.057643   0.105364  0.019917   \n","PAY_2                       -0.296382 -0.070771   0.121566  0.024199   \n","PAY_3                       -0.286123 -0.066096   0.114025  0.032688   \n","PAY_4                       -0.267460 -0.060173   0.108793  0.033122   \n","PAY_5                       -0.249411 -0.055064   0.097520  0.035629   \n","PAY_6                       -0.235195 -0.044008   0.082316  0.034345   \n","BILL_AMT1                    0.285430 -0.033642   0.023581 -0.023472   \n","BILL_AMT2                    0.278314 -0.031183   0.018749 -0.021602   \n","BILL_AMT3                    0.283236 -0.024563   0.013002 -0.024909   \n","BILL_AMT4                    0.293988 -0.021880  -0.000451 -0.023344   \n","BILL_AMT5                    0.295562 -0.017005  -0.007567 -0.025393   \n","BILL_AMT6                    0.290389 -0.016733  -0.009099 -0.021207   \n","PAY_AMT1                     0.195236 -0.000242  -0.037456 -0.005979   \n","PAY_AMT2                     0.178408 -0.001391  -0.030038 -0.008093   \n","PAY_AMT3                     0.210167 -0.008597  -0.039943 -0.003541   \n","PAY_AMT4                     0.203242 -0.002229  -0.038218 -0.012659   \n","PAY_AMT5                     0.217202 -0.001667  -0.040358 -0.001205   \n","PAY_AMT6                     0.219595 -0.002766  -0.037200 -0.006641   \n","default payment next month  -0.153520 -0.039961   0.028006 -0.024339   \n","\n","                                 AGE     PAY_0     PAY_2     PAY_3     PAY_4  \\\n","LIMIT_BAL                   0.144713 -0.271214 -0.296382 -0.286123 -0.267460   \n","SEX                        -0.090874 -0.057643 -0.070771 -0.066096 -0.060173   \n","EDUCATION                   0.175061  0.105364  0.121566  0.114025  0.108793   \n","MARRIAGE                   -0.414170  0.019917  0.024199  0.032688  0.033122   \n","AGE                         1.000000 -0.039447 -0.050148 -0.053048 -0.049722   \n","PAY_0                      -0.039447  1.000000  0.672164  0.574245  0.538841   \n","PAY_2                      -0.050148  0.672164  1.000000  0.766552  0.662067   \n","PAY_3                      -0.053048  0.574245  0.766552  1.000000  0.777359   \n","PAY_4                      -0.049722  0.538841  0.662067  0.777359  1.000000   \n","PAY_5                      -0.053826  0.509426  0.622780  0.686775  0.819835   \n","PAY_6                      -0.048773  0.474553  0.575501  0.632684  0.716449   \n","BILL_AMT1                   0.056239  0.187068  0.234887  0.208473  0.202812   \n","BILL_AMT2                   0.054283  0.189859  0.235257  0.237295  0.225816   \n","BILL_AMT3                   0.053710  0.179785  0.224146  0.227494  0.244983   \n","BILL_AMT4                   0.051353  0.179125  0.222237  0.227202  0.245917   \n","BILL_AMT5                   0.049345  0.180635  0.221348  0.225145  0.242902   \n","BILL_AMT6                   0.047613  0.176980  0.219403  0.222327  0.239154   \n","PAY_AMT1                    0.026147 -0.079269 -0.080701  0.001295 -0.009362   \n","PAY_AMT2                    0.021785 -0.070101 -0.058990 -0.066793 -0.001944   \n","PAY_AMT3                    0.029247 -0.070561 -0.055901 -0.053311 -0.069235   \n","PAY_AMT4                    0.021379 -0.064005 -0.046858 -0.046067 -0.043461   \n","PAY_AMT5                    0.022850 -0.058190 -0.037093 -0.035863 -0.033590   \n","PAY_AMT6                    0.019478 -0.058673 -0.036500 -0.035861 -0.026565   \n","default payment next month  0.013890  0.324794  0.263551  0.235253  0.216614   \n","\n","                               PAY_5             ...              BILL_AMT4  \\\n","LIMIT_BAL                  -0.249411             ...               0.293988   \n","SEX                        -0.055064             ...              -0.021880   \n","EDUCATION                   0.097520             ...              -0.000451   \n","MARRIAGE                    0.035629             ...              -0.023344   \n","AGE                        -0.053826             ...               0.051353   \n","PAY_0                       0.509426             ...               0.179125   \n","PAY_2                       0.622780             ...               0.222237   \n","PAY_3                       0.686775             ...               0.227202   \n","PAY_4                       0.819835             ...               0.245917   \n","PAY_5                       1.000000             ...               0.271915   \n","PAY_6                       0.816900             ...               0.266356   \n","BILL_AMT1                   0.206684             ...               0.860272   \n","BILL_AMT2                   0.226913             ...               0.892482   \n","BILL_AMT3                   0.243335             ...               0.923969   \n","BILL_AMT4                   0.271915             ...               1.000000   \n","BILL_AMT5                   0.269783             ...               0.940134   \n","BILL_AMT6                   0.262509             ...               0.900941   \n","PAY_AMT1                   -0.006089             ...               0.233012   \n","PAY_AMT2                   -0.003191             ...               0.207564   \n","PAY_AMT3                    0.009062             ...               0.300023   \n","PAY_AMT4                   -0.058299             ...               0.130191   \n","PAY_AMT5                   -0.033337             ...               0.160433   \n","PAY_AMT6                   -0.023027             ...               0.177637   \n","default payment next month  0.204149             ...              -0.010156   \n","\n","                            BILL_AMT5  BILL_AMT6  PAY_AMT1  PAY_AMT2  \\\n","LIMIT_BAL                    0.295562   0.290389  0.195236  0.178408   \n","SEX                         -0.017005  -0.016733 -0.000242 -0.001391   \n","EDUCATION                   -0.007567  -0.009099 -0.037456 -0.030038   \n","MARRIAGE                    -0.025393  -0.021207 -0.005979 -0.008093   \n","AGE                          0.049345   0.047613  0.026147  0.021785   \n","PAY_0                        0.180635   0.176980 -0.079269 -0.070101   \n","PAY_2                        0.221348   0.219403 -0.080701 -0.058990   \n","PAY_3                        0.225145   0.222327  0.001295 -0.066793   \n","PAY_4                        0.242902   0.239154 -0.009362 -0.001944   \n","PAY_5                        0.269783   0.262509 -0.006089 -0.003191   \n","PAY_6                        0.290894   0.285091 -0.001496 -0.005223   \n","BILL_AMT1                    0.829779   0.802650  0.140277  0.099355   \n","BILL_AMT2                    0.859778   0.831594  0.280365  0.100851   \n","BILL_AMT3                    0.883910   0.853320  0.244335  0.316936   \n","BILL_AMT4                    0.940134   0.900941  0.233012  0.207564   \n","BILL_AMT5                    1.000000   0.946197  0.217031  0.181246   \n","BILL_AMT6                    0.946197   1.000000  0.199965  0.172663   \n","PAY_AMT1                     0.217031   0.199965  1.000000  0.285576   \n","PAY_AMT2                     0.181246   0.172663  0.285576  1.000000   \n","PAY_AMT3                     0.252305   0.233770  0.252191  0.244770   \n","PAY_AMT4                     0.293118   0.250237  0.199558  0.180107   \n","PAY_AMT5                     0.141574   0.307729  0.148459  0.180908   \n","PAY_AMT6                     0.164184   0.115494  0.185735  0.157634   \n","default payment next month  -0.006760  -0.005372 -0.072929 -0.058579   \n","\n","                            PAY_AMT3  PAY_AMT4  PAY_AMT5  PAY_AMT6  \\\n","LIMIT_BAL                   0.210167  0.203242  0.217202  0.219595   \n","SEX                        -0.008597 -0.002229 -0.001667 -0.002766   \n","EDUCATION                  -0.039943 -0.038218 -0.040358 -0.037200   \n","MARRIAGE                   -0.003541 -0.012659 -0.001205 -0.006641   \n","AGE                         0.029247  0.021379  0.022850  0.019478   \n","PAY_0                      -0.070561 -0.064005 -0.058190 -0.058673   \n","PAY_2                      -0.055901 -0.046858 -0.037093 -0.036500   \n","PAY_3                      -0.053311 -0.046067 -0.035863 -0.035861   \n","PAY_4                      -0.069235 -0.043461 -0.033590 -0.026565   \n","PAY_5                       0.009062 -0.058299 -0.033337 -0.023027   \n","PAY_6                       0.005834  0.019018 -0.046434 -0.025299   \n","BILL_AMT1                   0.156887  0.158303  0.167026  0.179341   \n","BILL_AMT2                   0.150718  0.147398  0.157957  0.174256   \n","BILL_AMT3                   0.130011  0.143405  0.179712  0.182326   \n","BILL_AMT4                   0.300023  0.130191  0.160433  0.177637   \n","BILL_AMT5                   0.252305  0.293118  0.141574  0.164184   \n","BILL_AMT6                   0.233770  0.250237  0.307729  0.115494   \n","PAY_AMT1                    0.252191  0.199558  0.148459  0.185735   \n","PAY_AMT2                    0.244770  0.180107  0.180908  0.157634   \n","PAY_AMT3                    1.000000  0.216325  0.159214  0.162740   \n","PAY_AMT4                    0.216325  1.000000  0.151830  0.157834   \n","PAY_AMT5                    0.159214  0.151830  1.000000  0.154896   \n","PAY_AMT6                    0.162740  0.157834  0.154896  1.000000   \n","default payment next month -0.056250 -0.056827 -0.055124 -0.053183   \n","\n","                            default payment next month  \n","LIMIT_BAL                                    -0.153520  \n","SEX                                          -0.039961  \n","EDUCATION                                     0.028006  \n","MARRIAGE                                     -0.024339  \n","AGE                                           0.013890  \n","PAY_0                                         0.324794  \n","PAY_2                                         0.263551  \n","PAY_3                                         0.235253  \n","PAY_4                                         0.216614  \n","PAY_5                                         0.204149  \n","PAY_6                                         0.186866  \n","BILL_AMT1                                    -0.019644  \n","BILL_AMT2                                    -0.014193  \n","BILL_AMT3                                    -0.014076  \n","BILL_AMT4                                    -0.010156  \n","BILL_AMT5                                    -0.006760  \n","BILL_AMT6                                    -0.005372  \n","PAY_AMT1                                     -0.072929  \n","PAY_AMT2                                     -0.058579  \n","PAY_AMT3                                     -0.056250  \n","PAY_AMT4                                     -0.056827  \n","PAY_AMT5                                     -0.055124  \n","PAY_AMT6                                     -0.053183  \n","default payment next month                    1.000000  \n","\n","[24 rows x 24 columns]"]},"metadata":{"tags":[]},"execution_count":20}]},{"metadata":{"id":"f0lEQzbtsPgA","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":499},"outputId":"8977aaff-fc85-4d6d-f020-cc0f540f80d3","executionInfo":{"status":"ok","timestamp":1529472964396,"user_tz":240,"elapsed":880,"user":{"displayName":"Bei Ning","photoUrl":"//lh6.googleusercontent.com/-MkDu8lm6Q8A/AAAAAAAAAAI/AAAAAAAAAKU/kSp5LEApHT0/s50-c-k-no/photo.jpg","userId":"104532927764063449706"}}},"cell_type":"code","source":["# 用Seaborn生成热图\n","import seaborn as sns\n","import matplotlib.style as style\n","# 选用一个干净的主题\n","style.use('fivethirtyeight')\n","sns.heatmap(credit_card_default.corr())"],"execution_count":21,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<matplotlib.axes._subplots.AxesSubplot at 0x7f1fdc6a4550>"]},"metadata":{"tags":[]},"execution_count":21},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAmUAAAHRCAYAAAArPM7ZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n","text/plain":["<matplotlib.figure.Figure at 0x7f1fdc6bbbe0>"]},"metadata":{"tags":[]}}]},{"metadata":{"id":"Oz0sNdYQtH84","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":442},"outputId":"d77aa5ea-6a4e-4417-c93d-e811c1016e3d","executionInfo":{"status":"ok","timestamp":1529473186150,"user_tz":240,"elapsed":332,"user":{"displayName":"Bei Ning","photoUrl":"//lh6.googleusercontent.com/-MkDu8lm6Q8A/AAAAAAAAAAI/AAAAAAAAAKU/kSp5LEApHT0/s50-c-k-no/photo.jpg","userId":"104532927764063449706"}}},"cell_type":"code","source":["# 只有特征和响应的相关性\n","credit_card_default.corr()['default payment next month'] "],"execution_count":22,"outputs":[{"output_type":"execute_result","data":{"text/plain":["LIMIT_BAL                    -0.153520\n","SEX                          -0.039961\n","EDUCATION                     0.028006\n","MARRIAGE                     -0.024339\n","AGE                           0.013890\n","PAY_0                         0.324794\n","PAY_2                         0.263551\n","PAY_3                         0.235253\n","PAY_4                         0.216614\n","PAY_5                         0.204149\n","PAY_6                         0.186866\n","BILL_AMT1                    -0.019644\n","BILL_AMT2                    -0.014193\n","BILL_AMT3                    -0.014076\n","BILL_AMT4                    -0.010156\n","BILL_AMT5                    -0.006760\n","BILL_AMT6                    -0.005372\n","PAY_AMT1                     -0.072929\n","PAY_AMT2                     -0.058579\n","PAY_AMT3                     -0.056250\n","PAY_AMT4                     -0.056827\n","PAY_AMT5                     -0.055124\n","PAY_AMT6                     -0.053183\n","default payment next month    1.000000\n","Name: default payment next month, dtype: float64"]},"metadata":{"tags":[]},"execution_count":22}]},{"metadata":{"id":"gsoqT_8kttY8","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":442},"outputId":"29a023ff-a7a1-4e24-d554-4b1505cac32c","executionInfo":{"status":"ok","timestamp":1529473343769,"user_tz":240,"elapsed":390,"user":{"displayName":"Bei Ning","photoUrl":"//lh6.googleusercontent.com/-MkDu8lm6Q8A/AAAAAAAAAAI/AAAAAAAAAKU/kSp5LEApHT0/s50-c-k-no/photo.jpg","userId":"104532927764063449706"}}},"cell_type":"code","source":["# 只留下相关系数超过正负0.2的特征\n","\n","credit_card_default.corr()['default payment next month'].abs() > .2"],"execution_count":23,"outputs":[{"output_type":"execute_result","data":{"text/plain":["LIMIT_BAL                     False\n","SEX                           False\n","EDUCATION                     False\n","MARRIAGE                      False\n","AGE                           False\n","PAY_0                          True\n","PAY_2                          True\n","PAY_3                          True\n","PAY_4                          True\n","PAY_5                          True\n","PAY_6                         False\n","BILL_AMT1                     False\n","BILL_AMT2                     False\n","BILL_AMT3                     False\n","BILL_AMT4                     False\n","BILL_AMT5                     False\n","BILL_AMT6                     False\n","PAY_AMT1                      False\n","PAY_AMT2                      False\n","PAY_AMT3                      False\n","PAY_AMT4                      False\n","PAY_AMT5                      False\n","PAY_AMT6                      False\n","default payment next month     True\n","Name: default payment next month, dtype: bool"]},"metadata":{"tags":[]},"execution_count":23}]},{"metadata":{"id":"Pz0EUnGZuHOZ","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":68},"outputId":"28127fdc-e07a-4dd4-9dce-6455f8600284","executionInfo":{"status":"ok","timestamp":1529473436439,"user_tz":240,"elapsed":457,"user":{"displayName":"Bei Ning","photoUrl":"//lh6.googleusercontent.com/-MkDu8lm6Q8A/AAAAAAAAAAI/AAAAAAAAAKU/kSp5LEApHT0/s50-c-k-no/photo.jpg","userId":"104532927764063449706"}}},"cell_type":"code","source":["# 存储特征\n","highly_correlated_features = credit_card_default.columns[credit_card_default.corr()['default payment next month'].abs() > .2]\n","\n","highly_correlated_features"],"execution_count":24,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Index(['PAY_0', 'PAY_2', 'PAY_3', 'PAY_4', 'PAY_5',\n","       'default payment next month'],\n","      dtype='object')"]},"metadata":{"tags":[]},"execution_count":24}]},{"metadata":{"id":"VtxmlC_sucan","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":34},"outputId":"ba52e185-1e27-4741-8bfd-0998b63a7d7f","executionInfo":{"status":"ok","timestamp":1529473526062,"user_tz":240,"elapsed":366,"user":{"displayName":"Bei Ning","photoUrl":"//lh6.googleusercontent.com/-MkDu8lm6Q8A/AAAAAAAAAAI/AAAAAAAAAKU/kSp5LEApHT0/s50-c-k-no/photo.jpg","userId":"104532927764063449706"}}},"cell_type":"code","source":["# 删掉响应变量\n","highly_correlated_features = highly_correlated_features.drop('default payment next month')\n","\n","highly_correlated_features"],"execution_count":25,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Index(['PAY_0', 'PAY_2', 'PAY_3', 'PAY_4', 'PAY_5'], dtype='object')"]},"metadata":{"tags":[]},"execution_count":25}]},{"metadata":{"id":"9rCtzVkMunmk","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":202},"outputId":"0faa3d1f-1699-434d-da23-ed515108e9f7","executionInfo":{"status":"error","timestamp":1529812812405,"user_tz":240,"elapsed":482,"user":{"displayName":"Bei Ning","photoUrl":"//lh6.googleusercontent.com/-MkDu8lm6Q8A/AAAAAAAAAAI/AAAAAAAAAKU/kSp5LEApHT0/s50-c-k-no/photo.jpg","userId":"104532927764063449706"}}},"cell_type":"code","source":["# 只有5个高度关联的变量\n","X_subsetted = X[highly_correlated_features]\n","\n","get_best_model_and_accuracy(d_tree, tree_params, X_subsetted, y) "],"execution_count":16,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-16-747f41a84c71>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_subsetted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhighly_correlated_features\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mget_best_model_and_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_tree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtree_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_subsetted\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'highly_correlated_features' is not defined"]}]},{"metadata":{"id":"uZA5NepLvrkU","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["from sklearn.base import TransformerMixin, BaseEstimator\n","\n","class CustomCorrelationChooser(TransformerMixin, BaseEstimator):\n","    def __init__(self, response, cols_to_keep=[], threshold=None):\n","        # 保存响应变量\n","        self.response = response\n","        # 保存阈值\n","        self.threshold = threshold\n","        # 初始化一个变量，存放要保留的特征名\n","        self.cols_to_keep = cols_to_keep\n","        \n","    def transform(self, X):\n","        # 转换会选择合适的列\n","        return X[self.cols_to_keep]\n","        \n","    def fit(self, X, *_):\n","        # 创建新的DataFrame，存放特征和响应\n","        df = pd.concat([X, self.response], axis=1)\n","        # 保存高于阈值的列的名称\n","        self.cols_to_keep = df.columns[df.corr()[df.columns[-1]].abs() > self.threshold]\n","        # 只保留X的列，去掉响应变量\n","        self.cols_to_keep = [c for c in self.cols_to_keep if c in X.columns]\n","        return self"],"execution_count":0,"outputs":[]},{"metadata":{"id":"2YuC2mUVwHAZ","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":34},"outputId":"334fd191-dc46-4509-f489-7bbd03a1dc51","executionInfo":{"status":"ok","timestamp":1529813368067,"user_tz":240,"elapsed":545,"user":{"displayName":"Bei Ning","photoUrl":"//lh6.googleusercontent.com/-MkDu8lm6Q8A/AAAAAAAAAAI/AAAAAAAAAKU/kSp5LEApHT0/s50-c-k-no/photo.jpg","userId":"104532927764063449706"}}},"cell_type":"code","source":["# 实例化特征选择器\n","ccc = CustomCorrelationChooser(threshold=.2, response=y)\n","ccc.fit(X)\n","\n","ccc.cols_to_keep"],"execution_count":25,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['PAY_0', 'PAY_2', 'PAY_3', 'PAY_4', 'PAY_5']"]},"metadata":{"tags":[]},"execution_count":25}]},{"metadata":{"id":"sg1vy53NwT3w","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":204},"outputId":"950399ce-af2b-4598-fde7-77f17422e371","executionInfo":{"status":"ok","timestamp":1529474009407,"user_tz":240,"elapsed":488,"user":{"displayName":"Bei Ning","photoUrl":"//lh6.googleusercontent.com/-MkDu8lm6Q8A/AAAAAAAAAAI/AAAAAAAAAKU/kSp5LEApHT0/s50-c-k-no/photo.jpg","userId":"104532927764063449706"}}},"cell_type":"code","source":["ccc.transform(X).head()"],"execution_count":29,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>PAY_0</th>\n","      <th>PAY_2</th>\n","      <th>PAY_3</th>\n","      <th>PAY_4</th>\n","      <th>PAY_5</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>-1</td>\n","      <td>-1</td>\n","      <td>-2</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>-1</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>-1</td>\n","      <td>0</td>\n","      <td>-1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   PAY_0  PAY_2  PAY_3  PAY_4  PAY_5\n","0      2      2     -1     -1     -2\n","1     -1      2      0      0      0\n","2      0      0      0      0      0\n","3      0      0      0      0      0\n","4     -1      0     -1      0      0"]},"metadata":{"tags":[]},"execution_count":29}]},{"metadata":{"id":"ftagVTMlwq09","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":54},"outputId":"7bd44f05-f10c-4f91-f8a7-1084129e5ae9","executionInfo":{"status":"ok","timestamp":1529813527194,"user_tz":240,"elapsed":616,"user":{"displayName":"Bei Ning","photoUrl":"//lh6.googleusercontent.com/-MkDu8lm6Q8A/AAAAAAAAAAI/AAAAAAAAAKU/kSp5LEApHT0/s50-c-k-no/photo.jpg","userId":"104532927764063449706"}}},"cell_type":"code","source":["from copy import deepcopy\n","\n","# 使用响应变量初始化特征选择器\n","ccc = CustomCorrelationChooser(response=y)\n","\n","# 创建流水线，包括选择器\n","ccc_pipe = Pipeline([('correlation_select', ccc), \n"," ('classifier', d_tree)])\n","\n","tree_pipe_params = {'classifier__max_depth': \n","                    [None, 1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21]}\n","\n","# 复制决策树的参数\n","ccc_pipe_params = deepcopy(tree_pipe_params)\n","\n","# 更新决策树的参数选择\n","ccc_pipe_params.update({'correlation_select__threshold':[0, .1, .2, .3]})\n","\n","print(ccc_pipe_params)  #{'correlation_select__threshold': [0, 0.1, 0.2, 0.3], 'classifier__max_depth': [None, 1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21]}"],"execution_count":34,"outputs":[{"output_type":"stream","text":["{'classifier__max_depth': [None, 1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21], 'correlation_select__threshold': [0, 0.1, 0.2, 0.3]}\n"],"name":"stdout"}]},{"metadata":{"id":"eL4jCSA5_d7_","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["\n","# 比原来好一点，而且很快\n","get_best_model_and_accuracy(ccc_pipe, ccc_pipe_params, X, y) "],"execution_count":0,"outputs":[]},{"metadata":{"id":"aG0fTzPjxt5p","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":34},"outputId":"a9c67980-60df-40f8-b6ee-7ff0789a29ed","executionInfo":{"status":"ok","timestamp":1529474390622,"user_tz":240,"elapsed":340,"user":{"displayName":"Bei Ning","photoUrl":"//lh6.googleusercontent.com/-MkDu8lm6Q8A/AAAAAAAAAAI/AAAAAAAAAKU/kSp5LEApHT0/s50-c-k-no/photo.jpg","userId":"104532927764063449706"}}},"cell_type":"code","source":["# 阈值是0.1\n","ccc = CustomCorrelationChooser(threshold=0.1, response=y)\n","ccc.fit(X)\n","\n","# 保留了什么？\n","ccc.cols_to_keep"],"execution_count":33,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['LIMIT_BAL', 'PAY_0', 'PAY_2', 'PAY_3', 'PAY_4', 'PAY_5', 'PAY_6']"]},"metadata":{"tags":[]},"execution_count":33}]},{"metadata":{"id":"a9zweOE70rb8","colab_type":"text"},"cell_type":"markdown","source":["##### 使用假设检验\n"]},{"metadata":{"id":"kN-w9_4H0sQ_","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# SelectKBest在给定目标函数后选择k个最高分\n","from sklearn.feature_selection import SelectKBest\n","\n","# ANOVA测试\n","from sklearn.feature_selection import f_classif\n","\n","# f_classif 可以使用负数 但不是所有类都支持\n","# chi2（卡方）也很常用，但只支持正数\n","# 回归分析有自己的假设检验"],"execution_count":0,"outputs":[]},{"metadata":{"id":"5tB7qRPY8JdO","colab_type":"text"},"cell_type":"markdown","source":["###### P值排列\n"]},{"metadata":{"id":"p2WiE2Q18IJl","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# 只保留最佳的5个特征\n","k_best = SelectKBest(f_classif, k=5)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"gvsYSAEp8eUI","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":136},"outputId":"c67d9986-060b-424f-e212-09dbed9ad44c","executionInfo":{"status":"ok","timestamp":1529812825586,"user_tz":240,"elapsed":396,"user":{"displayName":"Bei Ning","photoUrl":"//lh6.googleusercontent.com/-MkDu8lm6Q8A/AAAAAAAAAAI/AAAAAAAAAKU/kSp5LEApHT0/s50-c-k-no/photo.jpg","userId":"104532927764063449706"}}},"cell_type":"code","source":["# 选择最佳特征后的矩阵\n","k_best.fit_transform(X, y)"],"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[ 2,  2, -1, -1, -2],\n","       [-1,  2,  0,  0,  0],\n","       [ 0,  0,  0,  0,  0],\n","       ...,\n","       [ 4,  3,  2, -1,  0],\n","       [ 1, -1,  0,  0,  0],\n","       [ 0,  0,  0,  0,  0]])"]},"metadata":{"tags":[]},"execution_count":18}]},{"metadata":{"id":"gptHAlWQ9HIv","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":204},"outputId":"99bf0994-2b92-4d1c-c1b6-8c4fcda2a9fc","executionInfo":{"status":"ok","timestamp":1529812938957,"user_tz":240,"elapsed":361,"user":{"displayName":"Bei Ning","photoUrl":"//lh6.googleusercontent.com/-MkDu8lm6Q8A/AAAAAAAAAAI/AAAAAAAAAKU/kSp5LEApHT0/s50-c-k-no/photo.jpg","userId":"104532927764063449706"}}},"cell_type":"code","source":["# 取列的p值\n","k_best.pvalues_\n","\n","# 特征和p值组成DataFrame\n","# 按p值排列\n","p_values = pd.DataFrame({'column': X.columns, 'p_value': k_best.pvalues_}).sort_values('p_value')\n","\n","# 前5个特征\n","p_values.head()"],"execution_count":19,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>column</th>\n","      <th>p_value</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>5</th>\n","      <td>PAY_0</td>\n","      <td>0.000000e+00</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>PAY_2</td>\n","      <td>0.000000e+00</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>PAY_3</td>\n","      <td>0.000000e+00</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>PAY_4</td>\n","      <td>1.899297e-315</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>PAY_5</td>\n","      <td>1.126608e-279</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  column        p_value\n","5  PAY_0   0.000000e+00\n","6  PAY_2   0.000000e+00\n","7  PAY_3   0.000000e+00\n","8  PAY_4  1.899297e-315\n","9  PAY_5  1.126608e-279"]},"metadata":{"tags":[]},"execution_count":19}]},{"metadata":{"id":"DgdaDQzB-E6e","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":669},"outputId":"c0681e8e-9693-4bba-e6fd-64b3fabf0dbb","executionInfo":{"status":"ok","timestamp":1529813170733,"user_tz":240,"elapsed":263,"user":{"displayName":"Bei Ning","photoUrl":"//lh6.googleusercontent.com/-MkDu8lm6Q8A/AAAAAAAAAAI/AAAAAAAAAKU/kSp5LEApHT0/s50-c-k-no/photo.jpg","userId":"104532927764063449706"}}},"cell_type":"code","source":["# 低p值的特征\n","p_values[p_values['p_value'] < .05]"],"execution_count":20,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>column</th>\n","      <th>p_value</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>5</th>\n","      <td>PAY_0</td>\n","      <td>0.000000e+00</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>PAY_2</td>\n","      <td>0.000000e+00</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>PAY_3</td>\n","      <td>0.000000e+00</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>PAY_4</td>\n","      <td>1.899297e-315</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>PAY_5</td>\n","      <td>1.126608e-279</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>PAY_6</td>\n","      <td>7.296740e-234</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>LIMIT_BAL</td>\n","      <td>1.302244e-157</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>PAY_AMT1</td>\n","      <td>1.146488e-36</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>PAY_AMT2</td>\n","      <td>3.166657e-24</td>\n","    </tr>\n","    <tr>\n","      <th>20</th>\n","      <td>PAY_AMT4</td>\n","      <td>6.830942e-23</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>PAY_AMT3</td>\n","      <td>1.841770e-22</td>\n","    </tr>\n","    <tr>\n","      <th>21</th>\n","      <td>PAY_AMT5</td>\n","      <td>1.241345e-21</td>\n","    </tr>\n","    <tr>\n","      <th>22</th>\n","      <td>PAY_AMT6</td>\n","      <td>3.033589e-20</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>SEX</td>\n","      <td>4.395249e-12</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>EDUCATION</td>\n","      <td>1.225038e-06</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>MARRIAGE</td>\n","      <td>2.485364e-05</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>BILL_AMT1</td>\n","      <td>6.673295e-04</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>BILL_AMT2</td>\n","      <td>1.395736e-02</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>BILL_AMT3</td>\n","      <td>1.476998e-02</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>AGE</td>\n","      <td>1.613685e-02</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["       column        p_value\n","5       PAY_0   0.000000e+00\n","6       PAY_2   0.000000e+00\n","7       PAY_3   0.000000e+00\n","8       PAY_4  1.899297e-315\n","9       PAY_5  1.126608e-279\n","10      PAY_6  7.296740e-234\n","0   LIMIT_BAL  1.302244e-157\n","17   PAY_AMT1   1.146488e-36\n","18   PAY_AMT2   3.166657e-24\n","20   PAY_AMT4   6.830942e-23\n","19   PAY_AMT3   1.841770e-22\n","21   PAY_AMT5   1.241345e-21\n","22   PAY_AMT6   3.033589e-20\n","1         SEX   4.395249e-12\n","2   EDUCATION   1.225038e-06\n","3    MARRIAGE   2.485364e-05\n","11  BILL_AMT1   6.673295e-04\n","12  BILL_AMT2   1.395736e-02\n","13  BILL_AMT3   1.476998e-02\n","4         AGE   1.613685e-02"]},"metadata":{"tags":[]},"execution_count":20}]},{"metadata":{"id":"d7qdNrNA-Xm1","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":142},"outputId":"99392b80-6ba0-41b3-87e6-c3a1998b410e","executionInfo":{"status":"ok","timestamp":1529813244113,"user_tz":240,"elapsed":261,"user":{"displayName":"Bei Ning","photoUrl":"//lh6.googleusercontent.com/-MkDu8lm6Q8A/AAAAAAAAAAI/AAAAAAAAAKU/kSp5LEApHT0/s50-c-k-no/photo.jpg","userId":"104532927764063449706"}}},"cell_type":"code","source":["# 高p值的特征\n","p_values[p_values['p_value'] >= .05]"],"execution_count":21,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>column</th>\n","      <th>p_value</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>14</th>\n","      <td>BILL_AMT4</td>\n","      <td>0.078556</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>BILL_AMT5</td>\n","      <td>0.241634</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>BILL_AMT6</td>\n","      <td>0.352123</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["       column   p_value\n","14  BILL_AMT4  0.078556\n","15  BILL_AMT5  0.241634\n","16  BILL_AMT6  0.352123"]},"metadata":{"tags":[]},"execution_count":21}]},{"metadata":{"id":"yzw3U1rQ_VD2","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["from copy import deepcopy"],"execution_count":0,"outputs":[]},{"metadata":{"id":"nZfgeNDH-qZz","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":122},"outputId":"074fd1a0-64b3-46a7-8a0f-4b7b4756bc23","executionInfo":{"status":"ok","timestamp":1529813652645,"user_tz":240,"elapsed":104598,"user":{"displayName":"Bei Ning","photoUrl":"//lh6.googleusercontent.com/-MkDu8lm6Q8A/AAAAAAAAAAI/AAAAAAAAAKU/kSp5LEApHT0/s50-c-k-no/photo.jpg","userId":"104532927764063449706"}}},"cell_type":"code","source":["k_best = SelectKBest(f_classif)\n","\n","# 用SelectKBest建立流水线\n","select_k_pipe = Pipeline([('k_best', k_best), \n"," ('classifier', d_tree)])\n","\n","select_k_best_pipe_params = deepcopy(tree_pipe_params)\n","# all没有作用\n","select_k_best_pipe_params.update({'k_best__k':list(range(1,23)) + ['all']})\n","\n","print(select_k_best_pipe_params) # {'k_best__k': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 'all'], 'classifier__max_depth': [None, 1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21]}\n","\n","# 与相关特征选择器比较\n","get_best_model_and_accuracy(select_k_pipe, select_k_best_pipe_params, X, y)"],"execution_count":36,"outputs":[{"output_type":"stream","text":["{'classifier__max_depth': [None, 1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21], 'k_best__k': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 'all']}\n","Best Accuracy: 0.8206\n","Best Parameters: {'classifier__max_depth': 5, 'k_best__k': 7}\n","Average Time to Fit (s): 0.115\n","Average Time to Score (s): 0.003\n"],"name":"stdout"}]},{"metadata":{"id":"KOzV5IQU__oM","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["k_best = SelectKBest(f_classif, k=7)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"4eMeRdulABn8","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":266},"outputId":"825d1851-d48d-4b1b-c9ce-da1338fd6aff","executionInfo":{"status":"ok","timestamp":1529813672057,"user_tz":240,"elapsed":251,"user":{"displayName":"Bei Ning","photoUrl":"//lh6.googleusercontent.com/-MkDu8lm6Q8A/AAAAAAAAAAI/AAAAAAAAAKU/kSp5LEApHT0/s50-c-k-no/photo.jpg","userId":"104532927764063449706"}}},"cell_type":"code","source":["p_values.head(7)"],"execution_count":38,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>column</th>\n","      <th>p_value</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>5</th>\n","      <td>PAY_0</td>\n","      <td>0.000000e+00</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>PAY_2</td>\n","      <td>0.000000e+00</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>PAY_3</td>\n","      <td>0.000000e+00</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>PAY_4</td>\n","      <td>1.899297e-315</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>PAY_5</td>\n","      <td>1.126608e-279</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>PAY_6</td>\n","      <td>7.296740e-234</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>LIMIT_BAL</td>\n","      <td>1.302244e-157</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["       column        p_value\n","5       PAY_0   0.000000e+00\n","6       PAY_2   0.000000e+00\n","7       PAY_3   0.000000e+00\n","8       PAY_4  1.899297e-315\n","9       PAY_5  1.126608e-279\n","10      PAY_6  7.296740e-234\n","0   LIMIT_BAL  1.302244e-157"]},"metadata":{"tags":[]},"execution_count":38}]},{"metadata":{"id":"AIE0V-kZAOqm","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":85},"outputId":"c36e9c4b-9495-455f-d2ba-af112c9b0c8b","executionInfo":{"status":"ok","timestamp":1529813761315,"user_tz":240,"elapsed":3182,"user":{"displayName":"Bei Ning","photoUrl":"//lh6.googleusercontent.com/-MkDu8lm6Q8A/AAAAAAAAAAI/AAAAAAAAAKU/kSp5LEApHT0/s50-c-k-no/photo.jpg","userId":"104532927764063449706"}}},"cell_type":"code","source":["# 完整性测试\n","# 用最差的特征\n","the_worst_of_X = X[X.columns.drop(['LIMIT_BAL', 'PAY_0', 'PAY_2', 'PAY_3', 'PAY_4', 'PAY_5', 'PAY_6'])]\n","\n","# 如果选择的特征特别差\n","# 性能也会受影响\n","get_best_model_and_accuracy(d_tree, tree_params, the_worst_of_X, y)"],"execution_count":39,"outputs":[{"output_type":"stream","text":["Best Accuracy: 0.7839333333333334\n","Best Parameters: {'max_depth': 5}\n","Average Time to Fit (s): 0.162\n","Average Time to Score (s): 0.003\n"],"name":"stdout"}]},{"metadata":{"id":"1w7l6OJ-1oar","colab_type":"text"},"cell_type":"markdown","source":["##### 再议自然语言处理\n"]},{"metadata":{"id":"m57Xjx7i1mag","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":224},"outputId":"72f92f2a-149a-4150-92a9-a8125175464e","executionInfo":{"status":"ok","timestamp":1529815536844,"user_tz":240,"elapsed":1935,"user":{"displayName":"Bei Ning","photoUrl":"//lh6.googleusercontent.com/-MkDu8lm6Q8A/AAAAAAAAAAI/AAAAAAAAAKU/kSp5LEApHT0/s50-c-k-no/photo.jpg","userId":"104532927764063449706"}}},"cell_type":"code","source":["!wget https://raw.githubusercontent.com/PacktPublishing/Feature-Engineering-Made-Easy/master/Chapter04/twitter_sentiment.csv"],"execution_count":40,"outputs":[{"output_type":"stream","text":["--2018-06-24 04:45:36--  https://raw.githubusercontent.com/PacktPublishing/Feature-Engineering-Made-Easy/master/Chapter04/twitter_sentiment.csv\r\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\r\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 8664015 (8.3M) [text/plain]\n","Saving to: ‘twitter_sentiment.csv’\n","\n","twitter_sentiment.c 100%[===================>]   8.26M  28.9MB/s    in 0.3s    \n","\n","2018-06-24 04:45:36 (28.9 MB/s) - ‘twitter_sentiment.csv’ saved [8664015/8664015]\n","\n"],"name":"stdout"}]},{"metadata":{"id":"dd197jD-1rwr","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# 推文数据集\n","tweets = pd.read_csv('./twitter_sentiment.csv', encoding='latin1')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"M8cZrBD011ad","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":204},"outputId":"6555d540-1b1b-4b7e-a080-b307cc02397c","executionInfo":{"status":"ok","timestamp":1529475457865,"user_tz":240,"elapsed":496,"user":{"displayName":"Bei Ning","photoUrl":"//lh6.googleusercontent.com/-MkDu8lm6Q8A/AAAAAAAAAAI/AAAAAAAAAKU/kSp5LEApHT0/s50-c-k-no/photo.jpg","userId":"104532927764063449706"}}},"cell_type":"code","source":["tweets.head()"],"execution_count":36,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>ItemID</th>\n","      <th>Sentiment</th>\n","      <th>SentimentText</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>is so sad for my APL frie...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>I missed the New Moon trail...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>omg its already 7:30 :O</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>0</td>\n","      <td>.. Omgaga. Im sooo  im gunna CRy. I'...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>0</td>\n","      <td>i think mi bf is cheating on me!!!   ...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   ItemID  Sentiment                                      SentimentText\n","0       1          0                       is so sad for my APL frie...\n","1       2          0                     I missed the New Moon trail...\n","2       3          1                            omg its already 7:30 :O\n","3       4          0            .. Omgaga. Im sooo  im gunna CRy. I'...\n","4       5          0           i think mi bf is cheating on me!!!   ..."]},"metadata":{"tags":[]},"execution_count":36}]},{"metadata":{"id":"wylytq-MHKNw","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["tweets_X, tweets_y = tweets['SentimentText'], tweets['Sentiment']"],"execution_count":0,"outputs":[]},{"metadata":{"id":"itB6l2DbHOMQ","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":3197},"outputId":"d0036c49-03d8-4d0f-f258-5dac011b157f","executionInfo":{"status":"error","timestamp":1529816073023,"user_tz":240,"elapsed":499762,"user":{"displayName":"Bei Ning","photoUrl":"//lh6.googleusercontent.com/-MkDu8lm6Q8A/AAAAAAAAAAI/AAAAAAAAAKU/kSp5LEApHT0/s50-c-k-no/photo.jpg","userId":"104532927764063449706"}}},"cell_type":"code","source":["from sklearn.feature_extraction.text import CountVectorizer\n","# 导入朴素贝叶斯，加快处理 \n","from sklearn.naive_bayes import MultinomialNB\n","\n","featurizer = CountVectorizer()\n","\n","text_pipe = Pipeline([('featurizer', featurizer), \n","                 ('classify', MultinomialNB())])\n","\n","text_pipe_params = {'featurizer__ngram_range':[(1, 2)], \n","               'featurizer__max_features': [5000, 10000],\n","               'featurizer__min_df': [0., .1, .2, .3], \n","               'featurizer__max_df': [.7, .8, .9, 1.]}\n","\n","\n","get_best_model_and_accuracy(text_pipe, text_pipe_params, \n","                            tweets_X, tweets_y)"],"execution_count":43,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError('After pruning, no terms remain. Try a lower min_df or a higher max_df.',)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError('After pruning, no terms remain. Try a lower min_df or a higher max_df.',)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError('After pruning, no terms remain. Try a lower min_df or a higher max_df.',)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError('After pruning, no terms remain. Try a lower min_df or a higher max_df.',)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError('After pruning, no terms remain. Try a lower min_df or a higher max_df.',)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError('After pruning, no terms remain. Try a lower min_df or a higher max_df.',)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError('After pruning, no terms remain. Try a lower min_df or a higher max_df.',)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError('After pruning, no terms remain. Try a lower min_df or a higher max_df.',)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError('After pruning, no terms remain. Try a lower min_df or a higher max_df.',)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError('After pruning, no terms remain. Try a lower min_df or a higher max_df.',)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError('After pruning, no terms remain. Try a lower min_df or a higher max_df.',)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError('After pruning, no terms remain. Try a lower min_df or a higher max_df.',)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError('After pruning, no terms remain. Try a lower min_df or a higher max_df.',)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError('After pruning, no terms remain. Try a lower min_df or a higher max_df.',)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError('After pruning, no terms remain. Try a lower min_df or a higher max_df.',)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError('After pruning, no terms remain. Try a lower min_df or a higher max_df.',)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError('After pruning, no terms remain. Try a lower min_df or a higher max_df.',)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError('After pruning, no terms remain. Try a lower min_df or a higher max_df.',)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError('After pruning, no terms remain. Try a lower min_df or a higher max_df.',)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError('After pruning, no terms remain. Try a lower min_df or a higher max_df.',)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError('After pruning, no terms remain. Try a lower min_df or a higher max_df.',)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n"],"name":"stderr"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-43-a704986a1c9d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m get_best_model_and_accuracy(text_pipe, text_pipe_params, \n\u001b[0;32m---> 17\u001b[0;31m                             tweets_X, tweets_y)\n\u001b[0m","\u001b[0;32m<ipython-input-1-31398e513021>\u001b[0m in \u001b[0;36mget_best_model_and_accuracy\u001b[0;34m(model, params, X, y)\u001b[0m\n\u001b[1;32m      6\u001b[0m                         \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# 要搜索的参数\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m                         error_score=0.) # 如果报错 结果是0\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 拟合模型和参数\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;31m# 经典的精度\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Best Accuracy: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    637\u001b[0m                                   error_score=self.error_score)\n\u001b[1;32m    638\u001b[0m           for parameters, (train, test) in product(candidate_params,\n\u001b[0;32m--> 639\u001b[0;31m                                                    cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m         \u001b[0;31m# if one choose to see train score, \"out\" will contain train score info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    777\u001b[0m             \u001b[0;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    623\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 625\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    586\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0mcb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 588\u001b[0;31m         \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    589\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, error_score)\u001b[0m\n\u001b[1;32m    456\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    246\u001b[0m             \u001b[0mThis\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m         \"\"\"\n\u001b[0;32m--> 248\u001b[0;31m         \u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    211\u001b[0m                 Xt, fitted_transformer = fit_transform_one_cached(\n\u001b[1;32m    212\u001b[0m                     \u001b[0mcloned_transformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m                     **fit_params_steps[name])\n\u001b[0m\u001b[1;32m    214\u001b[0m                 \u001b[0;31m# Replace the transformer of the step with the fitted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                 \u001b[0;31m# transformer. This is necessary when loading the transformer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/memory.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 362\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall_and_shelve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_fit_transform_one\u001b[0;34m(transformer, weight, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    579\u001b[0m                        **fit_params):\n\u001b[1;32m    580\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'fit_transform'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 581\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    582\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m    867\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m         vocabulary, X = self._count_vocab(raw_documents,\n\u001b[0;32m--> 869\u001b[0;31m                                           self.fixed_vocabulary_)\n\u001b[0m\u001b[1;32m    870\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_count_vocab\u001b[0;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[1;32m    792\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[0;32min\u001b[0m \u001b[0manalyze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    793\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 794\u001b[0;31m                     \u001b[0mfeature_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    795\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mfeature_idx\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfeature_counter\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    796\u001b[0m                         \u001b[0mfeature_counter\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature_idx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"metadata":{"id":"QYHBCyPhIDYL","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# 更基础，但是用了SelectKBest的流水线\n","featurizer = CountVectorizer(ngram_range=(1, 2))\n","\n","select_k_text_pipe = Pipeline([('featurizer', featurizer), \n","                      ('select_k', SelectKBest()),\n","                      ('classify', MultinomialNB())])\n","\n","select_k_text_pipe_params = {'select_k__k': [1000, 5000]}\n","\n","get_best_model_and_accuracy(select_k_text_pipe, \n","                            select_k_text_pipe_params, \n","                            tweets_X, tweets_y)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"7erBGj1E1ly-","colab_type":"text"},"cell_type":"markdown","source":["###### 特征选择指标——基于树的模型\n"]},{"metadata":{"id":"-2rrGWW7K_cY","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":119},"outputId":"575285fd-cd0d-4306-fab5-6deaca537248","executionInfo":{"status":"ok","timestamp":1529816556937,"user_tz":240,"elapsed":1029,"user":{"displayName":"Bei Ning","photoUrl":"//lh6.googleusercontent.com/-MkDu8lm6Q8A/AAAAAAAAAAI/AAAAAAAAAKU/kSp5LEApHT0/s50-c-k-no/photo.jpg","userId":"104532927764063449706"}}},"cell_type":"code","source":["# 创建新的决策树分类器\n","tree = DecisionTreeClassifier()\n","\n","tree.fit(X, y)"],"execution_count":44,"outputs":[{"output_type":"execute_result","data":{"text/plain":["DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n","            max_features=None, max_leaf_nodes=None,\n","            min_impurity_decrease=0.0, min_impurity_split=None,\n","            min_samples_leaf=1, min_samples_split=2,\n","            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n","            splitter='best')"]},"metadata":{"tags":[]},"execution_count":44}]},{"metadata":{"id":"3H1yNtFRLXrN","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":204},"outputId":"92046a63-cfc4-40e1-95ea-ea1013c4369d","executionInfo":{"status":"ok","timestamp":1529816674069,"user_tz":240,"elapsed":536,"user":{"displayName":"Bei Ning","photoUrl":"//lh6.googleusercontent.com/-MkDu8lm6Q8A/AAAAAAAAAAI/AAAAAAAAAKU/kSp5LEApHT0/s50-c-k-no/photo.jpg","userId":"104532927764063449706"}}},"cell_type":"code","source":["# 注意：还有其他特征\n","\n","importances = pd.DataFrame({'importance': tree.feature_importances_, 'feature':X.columns}).sort_values('importance', ascending=False)\n","\n","importances.head()"],"execution_count":45,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>feature</th>\n","      <th>importance</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>5</th>\n","      <td>PAY_0</td>\n","      <td>0.162542</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>AGE</td>\n","      <td>0.072092</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>BILL_AMT1</td>\n","      <td>0.067903</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>LIMIT_BAL</td>\n","      <td>0.061725</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>PAY_AMT3</td>\n","      <td>0.055102</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      feature  importance\n","5       PAY_0    0.162542\n","4         AGE    0.072092\n","11  BILL_AMT1    0.067903\n","0   LIMIT_BAL    0.061725\n","19   PAY_AMT3    0.055102"]},"metadata":{"tags":[]},"execution_count":45}]},{"metadata":{"id":"bAyk7SREMmkr","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# 和SelectKBest相似，但不是统计测试\n","from sklearn.feature_selection import SelectFromModel"],"execution_count":0,"outputs":[]},{"metadata":{"id":"hTXN6wo7MxhJ","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# 实例化一个类，按照决策树分类器的内部指标排序重要性，选择特征\n","select_from_model = SelectFromModel(DecisionTreeClassifier(), \n"," threshold=.05)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"PSWSSgqlMxVo","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":34},"outputId":"a2b00f88-e39d-4cbb-9026-e83a65ba00d8","executionInfo":{"status":"ok","timestamp":1529817063300,"user_tz":240,"elapsed":1040,"user":{"displayName":"Bei Ning","photoUrl":"//lh6.googleusercontent.com/-MkDu8lm6Q8A/AAAAAAAAAAI/AAAAAAAAAKU/kSp5LEApHT0/s50-c-k-no/photo.jpg","userId":"104532927764063449706"}}},"cell_type":"code","source":["selected_X = select_from_model.fit_transform(X, y)\n","selected_X.shape"],"execution_count":48,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(30000, 8)"]},"metadata":{"tags":[]},"execution_count":48}]},{"metadata":{"id":"Gn3YhUfNNt8Y","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":3911},"outputId":"6ef35942-5cb0-427d-d54b-504057d28799","executionInfo":{"status":"error","timestamp":1529817320488,"user_tz":240,"elapsed":31517,"user":{"displayName":"Bei Ning","photoUrl":"//lh6.googleusercontent.com/-MkDu8lm6Q8A/AAAAAAAAAAI/AAAAAAAAAKU/kSp5LEApHT0/s50-c-k-no/photo.jpg","userId":"104532927764063449706"}}},"cell_type":"code","source":["# 为后面加速\n","tree_pipe_params = {'classifier__max_depth': [1, 3, 5, 7]}\n","\n","from sklearn.pipeline import Pipeline\n","\n","# 创建基于DecisionTreeClassifier的SelectFromModel\n","select = SelectFromModel(DecisionTreeClassifier())\n","\n","select_from_pipe = Pipeline([('select', select),\n","                             ('classifier', d_tree)])\n","\n","select_from_pipe_params = deepcopy(tree_pipe_params)\n","\n","select_from_pipe_params.update({\n"," 'select__threshold': [.01, .05, .1, .2, .25, .3, .4, .5, .6, \"mean\", \"median\", \"2.*mean\"],\n"," 'select__estimator__max_depth': [None, 1, 3, 5, 7]\n"," })\n","\n","print(select_from_pipe_params)  # {'select__threshold': [0.01, 0.05, 0.1, 'mean', 'median', '2.*mean'], 'select__estimator__max_depth': [None, 1, 3, 5, 7], 'classifier__max_depth': [1, 3, 5, 7]}\n","\n","\n","get_best_model_and_accuracy(select_from_pipe, \n"," select_from_pipe_params, \n"," X, y)"],"execution_count":49,"outputs":[{"output_type":"stream","text":["{'classifier__max_depth': [1, 3, 5, 7], 'select__threshold': [0.01, 0.05, 0.1, 0.2, 0.25, 0.3, 0.4, 0.5, 0.6, 'mean', 'median', '2.*mean'], 'select__estimator__max_depth': [None, 1, 3, 5, 7]}\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/base.py:80: UserWarning: No features were selected: either the data is too noisy or the selection test too strict.\n","  UserWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError('Found array with 0 feature(s) (shape=(20000, 0)) while a minimum of 1 is required.',)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/base.py:80: UserWarning: No features were selected: either the data is too noisy or the selection test too strict.\n","  UserWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError('Found array with 0 feature(s) (shape=(20000, 0)) while a minimum of 1 is required.',)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/base.py:80: UserWarning: No features were selected: either the data is too noisy or the selection test too strict.\n","  UserWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError('Found array with 0 feature(s) (shape=(20000, 0)) while a minimum of 1 is required.',)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/base.py:80: UserWarning: No features were selected: either the data is too noisy or the selection test too strict.\n","  UserWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError('Found array with 0 feature(s) (shape=(20000, 0)) while a minimum of 1 is required.',)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/base.py:80: UserWarning: No features were selected: either the data is too noisy or the selection test too strict.\n","  UserWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError('Found array with 0 feature(s) (shape=(20000, 0)) while a minimum of 1 is required.',)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/base.py:80: UserWarning: No features were selected: either the data is too noisy or the selection test too strict.\n","  UserWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError('Found array with 0 feature(s) (shape=(20000, 0)) while a minimum of 1 is required.',)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/base.py:80: UserWarning: No features were selected: either the data is too noisy or the selection test too strict.\n","  UserWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError('Found array with 0 feature(s) (shape=(20000, 0)) while a minimum of 1 is required.',)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/base.py:80: UserWarning: No features were selected: either the data is too noisy or the selection test too strict.\n","  UserWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError('Found array with 0 feature(s) (shape=(20000, 0)) while a minimum of 1 is required.',)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/base.py:80: UserWarning: No features were selected: either the data is too noisy or the selection test too strict.\n","  UserWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError('Found array with 0 feature(s) (shape=(20000, 0)) while a minimum of 1 is required.',)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/base.py:80: UserWarning: No features were selected: either the data is too noisy or the selection test too strict.\n","  UserWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError('Found array with 0 feature(s) (shape=(20000, 0)) while a minimum of 1 is required.',)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/base.py:80: UserWarning: No features were selected: either the data is too noisy or the selection test too strict.\n","  UserWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError('Found array with 0 feature(s) (shape=(20000, 0)) while a minimum of 1 is required.',)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/base.py:80: UserWarning: No features were selected: either the data is too noisy or the selection test too strict.\n","  UserWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError('Found array with 0 feature(s) (shape=(20000, 0)) while a minimum of 1 is required.',)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/base.py:80: UserWarning: No features were selected: either the data is too noisy or the selection test too strict.\n","  UserWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError('Found array with 0 feature(s) (shape=(20000, 0)) while a minimum of 1 is required.',)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/base.py:80: UserWarning: No features were selected: either the data is too noisy or the selection test too strict.\n","  UserWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError('Found array with 0 feature(s) (shape=(20000, 0)) while a minimum of 1 is required.',)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/base.py:80: UserWarning: No features were selected: either the data is too noisy or the selection test too strict.\n","  UserWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError('Found array with 0 feature(s) (shape=(20000, 0)) while a minimum of 1 is required.',)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/base.py:80: UserWarning: No features were selected: either the data is too noisy or the selection test too strict.\n","  UserWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError('Found array with 0 feature(s) (shape=(20000, 0)) while a minimum of 1 is required.',)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/base.py:80: UserWarning: No features were selected: either the data is too noisy or the selection test too strict.\n","  UserWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError('Found array with 0 feature(s) (shape=(20000, 0)) while a minimum of 1 is required.',)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/base.py:80: UserWarning: No features were selected: either the data is too noisy or the selection test too strict.\n","  UserWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError('Found array with 0 feature(s) (shape=(20000, 0)) while a minimum of 1 is required.',)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n"],"name":"stderr"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-49-5a664ef52269>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m get_best_model_and_accuracy(select_from_pipe, \n\u001b[1;32m     22\u001b[0m  \u001b[0mselect_from_pipe_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m  X, y)\n\u001b[0m","\u001b[0;32m<ipython-input-1-31398e513021>\u001b[0m in \u001b[0;36mget_best_model_and_accuracy\u001b[0;34m(model, params, X, y)\u001b[0m\n\u001b[1;32m      6\u001b[0m                         \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# 要搜索的参数\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m                         error_score=0.) # 如果报错，结果是0\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 拟合模型和参数\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;31m# 经典的精度\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Best Accuracy: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    637\u001b[0m                                   error_score=self.error_score)\n\u001b[1;32m    638\u001b[0m           for parameters, (train, test) in product(candidate_params,\n\u001b[0;32m--> 639\u001b[0;31m                                                    cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m         \u001b[0;31m# if one choose to see train score, \"out\" will contain train score info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    777\u001b[0m             \u001b[0;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    623\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 625\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    586\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0mcb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 588\u001b[0;31m         \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    589\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, error_score)\u001b[0m\n\u001b[1;32m    456\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    246\u001b[0m             \u001b[0mThis\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m         \"\"\"\n\u001b[0;32m--> 248\u001b[0;31m         \u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    211\u001b[0m                 Xt, fitted_transformer = fit_transform_one_cached(\n\u001b[1;32m    212\u001b[0m                     \u001b[0mcloned_transformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m                     **fit_params_steps[name])\n\u001b[0m\u001b[1;32m    214\u001b[0m                 \u001b[0;31m# Replace the transformer of the step with the fitted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                 \u001b[0;31m# transformer. This is necessary when loading the transformer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/memory.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 362\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall_and_shelve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_fit_transform_one\u001b[0;34m(transformer, weight, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    579\u001b[0m                        **fit_params):\n\u001b[1;32m    580\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'fit_transform'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 581\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    582\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    518\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    522\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/from_model.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    167\u001b[0m                 \"Since 'prefit=True', call transform directly\")\n\u001b[1;32m    168\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    788\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 790\u001b[0;31m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m    791\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    792\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    360\u001b[0m                                            min_impurity_split)\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 362\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"metadata":{"id":"vuQ3mqr2Xo9y","colab_type":"text"},"cell_type":"markdown","source":["###### 另一个特征重要性指标：线性模型参数\n"]},{"metadata":{"id":"0prj_8INXppA","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":2162},"outputId":"2e8bb1c6-6e99-44fa-f26c-e4b54c375474","executionInfo":{"status":"ok","timestamp":1529820008153,"user_tz":240,"elapsed":86816,"user":{"displayName":"Bei Ning","photoUrl":"//lh6.googleusercontent.com/-MkDu8lm6Q8A/AAAAAAAAAAI/AAAAAAAAAKU/kSp5LEApHT0/s50-c-k-no/photo.jpg","userId":"104532927764063449706"}}},"cell_type":"code","source":["# 用正则化后的逻辑回归进行选择\n","logistic_selector = SelectFromModel(LogisticRegression())\n","\n","# 新流水线，用LogistisRegression的参数进行排列\n","regularization_pipe = Pipeline([('select', logistic_selector), \n"," ('classifier', tree)])\n","\n","regularization_pipe_params = deepcopy(tree_pipe_params)\n","\n","# L1和L2正则化\n","regularization_pipe_params.update({\n"," 'select__threshold': [.01, .05, .1, \"mean\", \"median\", \"2.*mean\"],\n"," 'select__estimator__penalty': ['l1', 'l2'],\n"," })\n","\n","print(regularization_pipe_params)  # {'select__threshold': [0.01, 0.05, 0.1, 'mean', 'median', '2.*mean'], 'classifier__max_depth': [1, 3, 5, 7], 'select__estimator__penalty': ['l1', 'l2']}\n","\n","\n","get_best_model_and_accuracy(regularization_pipe, \n"," regularization_pipe_params, \n"," X, y)"],"execution_count":50,"outputs":[{"output_type":"stream","text":["{'classifier__max_depth': [1, 3, 5, 7], 'select__threshold': [0.01, 0.05, 0.1, 'mean', 'median', '2.*mean'], 'select__estimator__penalty': ['l1', 'l2']}\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/base.py:80: UserWarning: No features were selected: either the data is too noisy or the selection test too strict.\n","  UserWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError('Found array with 0 feature(s) (shape=(20000, 0)) while a minimum of 1 is required.',)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/base.py:80: UserWarning: No features were selected: either the data is too noisy or the selection test too strict.\n","  UserWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError('Found array with 0 feature(s) (shape=(20000, 0)) while a minimum of 1 is required.',)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/base.py:80: UserWarning: No features were selected: either the data is too noisy or the selection test too strict.\n","  UserWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError('Found array with 0 feature(s) (shape=(20000, 0)) while a minimum of 1 is required.',)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/base.py:80: UserWarning: No features were selected: either the data is too noisy or the selection test too strict.\n","  UserWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError('Found array with 0 feature(s) (shape=(20000, 0)) while a minimum of 1 is required.',)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/base.py:80: UserWarning: No features were selected: either the data is too noisy or the selection test too strict.\n","  UserWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError('Found array with 0 feature(s) (shape=(20000, 0)) while a minimum of 1 is required.',)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/base.py:80: UserWarning: No features were selected: either the data is too noisy or the selection test too strict.\n","  UserWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError('Found array with 0 feature(s) (shape=(20000, 0)) while a minimum of 1 is required.',)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/base.py:80: UserWarning: No features were selected: either the data is too noisy or the selection test too strict.\n","  UserWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError('Found array with 0 feature(s) (shape=(20000, 0)) while a minimum of 1 is required.',)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/base.py:80: UserWarning: No features were selected: either the data is too noisy or the selection test too strict.\n","  UserWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError('Found array with 0 feature(s) (shape=(20000, 0)) while a minimum of 1 is required.',)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/base.py:80: UserWarning: No features were selected: either the data is too noisy or the selection test too strict.\n","  UserWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError('Found array with 0 feature(s) (shape=(20000, 0)) while a minimum of 1 is required.',)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/base.py:80: UserWarning: No features were selected: either the data is too noisy or the selection test too strict.\n","  UserWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError('Found array with 0 feature(s) (shape=(20000, 0)) while a minimum of 1 is required.',)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/base.py:80: UserWarning: No features were selected: either the data is too noisy or the selection test too strict.\n","  UserWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError('Found array with 0 feature(s) (shape=(20000, 0)) while a minimum of 1 is required.',)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/base.py:80: UserWarning: No features were selected: either the data is too noisy or the selection test too strict.\n","  UserWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError('Found array with 0 feature(s) (shape=(20000, 0)) while a minimum of 1 is required.',)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/base.py:80: UserWarning: No features were selected: either the data is too noisy or the selection test too strict.\n","  UserWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError('Found array with 0 feature(s) (shape=(20000, 0)) while a minimum of 1 is required.',)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/base.py:80: UserWarning: No features were selected: either the data is too noisy or the selection test too strict.\n","  UserWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError('Found array with 0 feature(s) (shape=(20000, 0)) while a minimum of 1 is required.',)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/base.py:80: UserWarning: No features were selected: either the data is too noisy or the selection test too strict.\n","  UserWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError('Found array with 0 feature(s) (shape=(20000, 0)) while a minimum of 1 is required.',)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/base.py:80: UserWarning: No features were selected: either the data is too noisy or the selection test too strict.\n","  UserWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError('Found array with 0 feature(s) (shape=(20000, 0)) while a minimum of 1 is required.',)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/base.py:80: UserWarning: No features were selected: either the data is too noisy or the selection test too strict.\n","  UserWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError('Found array with 0 feature(s) (shape=(20000, 0)) while a minimum of 1 is required.',)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/base.py:80: UserWarning: No features were selected: either the data is too noisy or the selection test too strict.\n","  UserWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError('Found array with 0 feature(s) (shape=(20000, 0)) while a minimum of 1 is required.',)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/base.py:80: UserWarning: No features were selected: either the data is too noisy or the selection test too strict.\n","  UserWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError('Found array with 0 feature(s) (shape=(20000, 0)) while a minimum of 1 is required.',)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/base.py:80: UserWarning: No features were selected: either the data is too noisy or the selection test too strict.\n","  UserWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError('Found array with 0 feature(s) (shape=(20000, 0)) while a minimum of 1 is required.',)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/base.py:80: UserWarning: No features were selected: either the data is too noisy or the selection test too strict.\n","  UserWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError('Found array with 0 feature(s) (shape=(20000, 0)) while a minimum of 1 is required.',)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/base.py:80: UserWarning: No features were selected: either the data is too noisy or the selection test too strict.\n","  UserWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError('Found array with 0 feature(s) (shape=(20000, 0)) while a minimum of 1 is required.',)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/base.py:80: UserWarning: No features were selected: either the data is too noisy or the selection test too strict.\n","  UserWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError('Found array with 0 feature(s) (shape=(20000, 0)) while a minimum of 1 is required.',)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/base.py:80: UserWarning: No features were selected: either the data is too noisy or the selection test too strict.\n","  UserWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError('Found array with 0 feature(s) (shape=(20000, 0)) while a minimum of 1 is required.',)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["Best Accuracy: 0.8212\n","Best Parameters: {'classifier__max_depth': 5, 'select__estimator__penalty': 'l1', 'select__threshold': 0.01}\n","Average Time to Fit (s): 0.589\n","Average Time to Score (s): 0.002\n"],"name":"stdout"}]},{"metadata":{"id":"YFOSgoW_YUdZ","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":68},"outputId":"e37d37cb-63c5-455c-9c5a-07d573817c1b","executionInfo":{"status":"ok","timestamp":1529820072719,"user_tz":240,"elapsed":969,"user":{"displayName":"Bei Ning","photoUrl":"//lh6.googleusercontent.com/-MkDu8lm6Q8A/AAAAAAAAAAI/AAAAAAAAAKU/kSp5LEApHT0/s50-c-k-no/photo.jpg","userId":"104532927764063449706"}}},"cell_type":"code","source":["# 设置流水线最佳参数\n","regularization_pipe.set_params(**{'select__threshold': 0.01, \n"," 'classifier__max_depth': 5, \n"," 'select__estimator__penalty': 'l1'})\n","\n","# 拟合数据\n","regularization_pipe.steps[0][1].fit(X, y)\n","\n","# 列出选择的列\n","X.columns[regularization_pipe.steps[0][1].get_support()]"],"execution_count":51,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Index(['SEX', 'EDUCATION', 'MARRIAGE', 'PAY_0', 'PAY_2', 'PAY_3', 'PAY_4',\n","       'PAY_5'],\n","      dtype='object')"]},"metadata":{"tags":[]},"execution_count":51}]},{"metadata":{"id":"-RKUKfVcYtON","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":21710},"outputId":"5fc5fd0f-d79d-4f10-b048-5f0623fe2570","executionInfo":{"status":"error","timestamp":1529820665906,"user_tz":240,"elapsed":461616,"user":{"displayName":"Bei Ning","photoUrl":"//lh6.googleusercontent.com/-MkDu8lm6Q8A/AAAAAAAAAAI/AAAAAAAAAKU/kSp5LEApHT0/s50-c-k-no/photo.jpg","userId":"104532927764063449706"}}},"cell_type":"code","source":["# SVC是线性模型，用线性支持在欧几里得空间内分割数据\n","# 只能分割二分数据\n","from sklearn.svm import LinearSVC\n","\n","# 用SVC取参数\n","svc_selector = SelectFromModel(LinearSVC())\n","\n","svc_pipe = Pipeline([('select', svc_selector), \n"," ('classifier', tree)])\n","\n","svc_pipe_params = deepcopy(tree_pipe_params)\n","\n","svc_pipe_params.update({\n"," 'select__threshold': [.01, .05, .1, \"mean\", \"median\", \"2.*mean\"],\n"," 'select__estimator__penalty': ['l1', 'l2'],\n"," 'select__estimator__loss': ['squared_hinge', 'hinge'],\n"," 'select__estimator__dual': [True, False]\n"," })\n","\n","print(svc_pipe_params)  # 'select__estimator__loss': ['squared_hinge', 'hinge'], 'select__threshold': [0.01, 0.05, 0.1, 'mean', 'median', '2.*mean'], 'select__estimator__penalty': ['l1', 'l2'], 'classifier__max_depth': [1, 3, 5, 7], 'select__estimator__dual': [True, False]}\n","\n","get_best_model_and_accuracy(svc_pipe, \n"," svc_pipe_params, \n"," X, y) "],"execution_count":52,"outputs":[{"output_type":"stream","text":["{'classifier__max_depth': [1, 3, 5, 7], 'select__threshold': [0.01, 0.05, 0.1, 'mean', 'median', '2.*mean'], 'select__estimator__penalty': ['l1', 'l2'], 'select__estimator__loss': ['squared_hinge', 'hinge'], 'select__estimator__dual': [True, False]}\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/base.py:80: UserWarning: No features were selected: either the data is too noisy or the selection test too strict.\n","  UserWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError('Found array with 0 feature(s) (shape=(20000, 0)) while a minimum of 1 is required.',)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/base.py:80: UserWarning: No features were selected: either the data is too noisy or the selection test too strict.\n","  UserWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError('Found array with 0 feature(s) (shape=(20000, 0)) while a minimum of 1 is required.',)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/base.py:80: UserWarning: No features were selected: either the data is too noisy or the selection test too strict.\n","  UserWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError('Found array with 0 feature(s) (shape=(20000, 0)) while a minimum of 1 is required.',)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/base.py:80: UserWarning: No features were selected: either the data is too noisy or the selection test too strict.\n","  UserWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError('Found array with 0 feature(s) (shape=(20000, 0)) while a minimum of 1 is required.',)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/base.py:80: UserWarning: No features were selected: either the data is too noisy or the selection test too strict.\n","  UserWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError('Found array with 0 feature(s) (shape=(20000, 0)) while a minimum of 1 is required.',)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/base.py:80: UserWarning: No features were selected: either the data is too noisy or the selection test too strict.\n","  UserWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError('Found array with 0 feature(s) (shape=(20000, 0)) while a minimum of 1 is required.',)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/base.py:80: UserWarning: No features were selected: either the data is too noisy or the selection test too strict.\n","  UserWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError('Found array with 0 feature(s) (shape=(20000, 0)) while a minimum of 1 is required.',)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/base.py:80: UserWarning: No features were selected: either the data is too noisy or the selection test too strict.\n","  UserWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError('Found array with 0 feature(s) (shape=(20000, 0)) while a minimum of 1 is required.',)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/base.py:80: UserWarning: No features were selected: either the data is too noisy or the selection test too strict.\n","  UserWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError('Found array with 0 feature(s) (shape=(20000, 0)) while a minimum of 1 is required.',)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/base.py:80: UserWarning: No features were selected: either the data is too noisy or the selection test too strict.\n","  UserWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError('Found array with 0 feature(s) (shape=(20000, 0)) while a minimum of 1 is required.',)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/base.py:80: UserWarning: No features were selected: either the data is too noisy or the selection test too strict.\n","  UserWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError('Found array with 0 feature(s) (shape=(20000, 0)) while a minimum of 1 is required.',)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/base.py:80: UserWarning: No features were selected: either the data is too noisy or the selection test too strict.\n","  UserWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError('Found array with 0 feature(s) (shape=(20000, 0)) while a minimum of 1 is required.',)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/base.py:80: UserWarning: No features were selected: either the data is too noisy or the selection test too strict.\n","  UserWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError('Found array with 0 feature(s) (shape=(20000, 0)) while a minimum of 1 is required.',)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/base.py:80: UserWarning: No features were selected: either the data is too noisy or the selection test too strict.\n","  UserWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError('Found array with 0 feature(s) (shape=(20000, 0)) while a minimum of 1 is required.',)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/base.py:80: UserWarning: No features were selected: either the data is too noisy or the selection test too strict.\n","  UserWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError('Found array with 0 feature(s) (shape=(20000, 0)) while a minimum of 1 is required.',)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/base.py:80: UserWarning: No features were selected: either the data is too noisy or the selection test too strict.\n","  UserWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError('Found array with 0 feature(s) (shape=(20000, 0)) while a minimum of 1 is required.',)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/base.py:80: UserWarning: No features were selected: either the data is too noisy or the selection test too strict.\n","  UserWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError('Found array with 0 feature(s) (shape=(20000, 0)) while a minimum of 1 is required.',)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/base.py:80: UserWarning: No features were selected: either the data is too noisy or the selection test too strict.\n","  UserWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError('Found array with 0 feature(s) (shape=(20000, 0)) while a minimum of 1 is required.',)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/base.py:80: UserWarning: No features were selected: either the data is too noisy or the selection test too strict.\n","  UserWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError('Found array with 0 feature(s) (shape=(20000, 0)) while a minimum of 1 is required.',)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/base.py:80: UserWarning: No features were selected: either the data is too noisy or the selection test too strict.\n","  UserWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError('Found array with 0 feature(s) (shape=(20000, 0)) while a minimum of 1 is required.',)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/base.py:80: UserWarning: No features were selected: either the data is too noisy or the selection test too strict.\n","  UserWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError('Found array with 0 feature(s) (shape=(20000, 0)) while a minimum of 1 is required.',)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/base.py:80: UserWarning: No features were selected: either the data is too noisy or the selection test too strict.\n","  UserWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError('Found array with 0 feature(s) (shape=(20000, 0)) while a minimum of 1 is required.',)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/base.py:80: UserWarning: No features were selected: either the data is too noisy or the selection test too strict.\n","  UserWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError('Found array with 0 feature(s) (shape=(20000, 0)) while a minimum of 1 is required.',)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/base.py:80: UserWarning: No features were selected: either the data is too noisy or the selection test too strict.\n","  UserWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError('Found array with 0 feature(s) (shape=(20000, 0)) while a minimum of 1 is required.',)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/base.py:80: UserWarning: No features were selected: either the data is too noisy or the selection test too strict.\n","  UserWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError('Found array with 0 feature(s) (shape=(20000, 0)) while a minimum of 1 is required.',)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/base.py:80: UserWarning: No features were selected: either the data is too noisy or the selection test too strict.\n","  UserWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError('Found array with 0 feature(s) (shape=(20000, 0)) while a minimum of 1 is required.',)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/base.py:80: UserWarning: No features were selected: either the data is too noisy or the selection test too strict.\n","  UserWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError('Found array with 0 feature(s) (shape=(20000, 0)) while a minimum of 1 is required.',)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=False\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=False\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=False\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=False\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=False\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=False\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=False\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=False\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=False\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=False\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=False\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=False\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=False\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=False\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=False\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=False\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=False\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=False\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l2' and loss='hinge' are not supported when dual=False, Parameters: penalty='l2', loss='hinge', dual=False\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l2' and loss='hinge' are not supported when dual=False, Parameters: penalty='l2', loss='hinge', dual=False\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l2' and loss='hinge' are not supported when dual=False, Parameters: penalty='l2', loss='hinge', dual=False\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l2' and loss='hinge' are not supported when dual=False, Parameters: penalty='l2', loss='hinge', dual=False\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l2' and loss='hinge' are not supported when dual=False, Parameters: penalty='l2', loss='hinge', dual=False\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l2' and loss='hinge' are not supported when dual=False, Parameters: penalty='l2', loss='hinge', dual=False\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l2' and loss='hinge' are not supported when dual=False, Parameters: penalty='l2', loss='hinge', dual=False\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l2' and loss='hinge' are not supported when dual=False, Parameters: penalty='l2', loss='hinge', dual=False\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l2' and loss='hinge' are not supported when dual=False, Parameters: penalty='l2', loss='hinge', dual=False\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l2' and loss='hinge' are not supported when dual=False, Parameters: penalty='l2', loss='hinge', dual=False\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l2' and loss='hinge' are not supported when dual=False, Parameters: penalty='l2', loss='hinge', dual=False\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l2' and loss='hinge' are not supported when dual=False, Parameters: penalty='l2', loss='hinge', dual=False\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l2' and loss='hinge' are not supported when dual=False, Parameters: penalty='l2', loss='hinge', dual=False\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l2' and loss='hinge' are not supported when dual=False, Parameters: penalty='l2', loss='hinge', dual=False\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l2' and loss='hinge' are not supported when dual=False, Parameters: penalty='l2', loss='hinge', dual=False\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l2' and loss='hinge' are not supported when dual=False, Parameters: penalty='l2', loss='hinge', dual=False\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l2' and loss='hinge' are not supported when dual=False, Parameters: penalty='l2', loss='hinge', dual=False\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l2' and loss='hinge' are not supported when dual=False, Parameters: penalty='l2', loss='hinge', dual=False\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/base.py:80: UserWarning: No features were selected: either the data is too noisy or the selection test too strict.\n","  UserWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError('Found array with 0 feature(s) (shape=(20000, 0)) while a minimum of 1 is required.',)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/base.py:80: UserWarning: No features were selected: either the data is too noisy or the selection test too strict.\n","  UserWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError('Found array with 0 feature(s) (shape=(20000, 0)) while a minimum of 1 is required.',)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/base.py:80: UserWarning: No features were selected: either the data is too noisy or the selection test too strict.\n","  UserWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError('Found array with 0 feature(s) (shape=(20000, 0)) while a minimum of 1 is required.',)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/base.py:80: UserWarning: No features were selected: either the data is too noisy or the selection test too strict.\n","  UserWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError('Found array with 0 feature(s) (shape=(20000, 0)) while a minimum of 1 is required.',)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/base.py:80: UserWarning: No features were selected: either the data is too noisy or the selection test too strict.\n","  UserWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError('Found array with 0 feature(s) (shape=(20000, 0)) while a minimum of 1 is required.',)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/base.py:80: UserWarning: No features were selected: either the data is too noisy or the selection test too strict.\n","  UserWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError('Found array with 0 feature(s) (shape=(20000, 0)) while a minimum of 1 is required.',)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/base.py:80: UserWarning: No features were selected: either the data is too noisy or the selection test too strict.\n","  UserWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError('Found array with 0 feature(s) (shape=(20000, 0)) while a minimum of 1 is required.',)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/base.py:80: UserWarning: No features were selected: either the data is too noisy or the selection test too strict.\n","  UserWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError('Found array with 0 feature(s) (shape=(20000, 0)) while a minimum of 1 is required.',)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/base.py:80: UserWarning: No features were selected: either the data is too noisy or the selection test too strict.\n","  UserWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError('Found array with 0 feature(s) (shape=(20000, 0)) while a minimum of 1 is required.',)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/base.py:80: UserWarning: No features were selected: either the data is too noisy or the selection test too strict.\n","  UserWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError('Found array with 0 feature(s) (shape=(20000, 0)) while a minimum of 1 is required.',)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/base.py:80: UserWarning: No features were selected: either the data is too noisy or the selection test too strict.\n","  UserWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError('Found array with 0 feature(s) (shape=(20000, 0)) while a minimum of 1 is required.',)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/base.py:80: UserWarning: No features were selected: either the data is too noisy or the selection test too strict.\n","  UserWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError('Found array with 0 feature(s) (shape=(20000, 0)) while a minimum of 1 is required.',)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/base.py:80: UserWarning: No features were selected: either the data is too noisy or the selection test too strict.\n","  UserWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError('Found array with 0 feature(s) (shape=(20000, 0)) while a minimum of 1 is required.',)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/base.py:80: UserWarning: No features were selected: either the data is too noisy or the selection test too strict.\n","  UserWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError('Found array with 0 feature(s) (shape=(20000, 0)) while a minimum of 1 is required.',)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/base.py:80: UserWarning: No features were selected: either the data is too noisy or the selection test too strict.\n","  UserWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError('Found array with 0 feature(s) (shape=(20000, 0)) while a minimum of 1 is required.',)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/base.py:80: UserWarning: No features were selected: either the data is too noisy or the selection test too strict.\n","  UserWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError('Found array with 0 feature(s) (shape=(20000, 0)) while a minimum of 1 is required.',)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/base.py:80: UserWarning: No features were selected: either the data is too noisy or the selection test too strict.\n","  UserWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError('Found array with 0 feature(s) (shape=(20000, 0)) while a minimum of 1 is required.',)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/base.py:80: UserWarning: No features were selected: either the data is too noisy or the selection test too strict.\n","  UserWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError('Found array with 0 feature(s) (shape=(20000, 0)) while a minimum of 1 is required.',)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/base.py:80: UserWarning: No features were selected: either the data is too noisy or the selection test too strict.\n","  UserWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError('Found array with 0 feature(s) (shape=(20000, 0)) while a minimum of 1 is required.',)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/base.py:80: UserWarning: No features were selected: either the data is too noisy or the selection test too strict.\n","  UserWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError('Found array with 0 feature(s) (shape=(20000, 0)) while a minimum of 1 is required.',)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/base.py:80: UserWarning: No features were selected: either the data is too noisy or the selection test too strict.\n","  UserWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError('Found array with 0 feature(s) (shape=(20000, 0)) while a minimum of 1 is required.',)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/base.py:80: UserWarning: No features were selected: either the data is too noisy or the selection test too strict.\n","  UserWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError('Found array with 0 feature(s) (shape=(20000, 0)) while a minimum of 1 is required.',)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/base.py:80: UserWarning: No features were selected: either the data is too noisy or the selection test too strict.\n","  UserWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError('Found array with 0 feature(s) (shape=(20000, 0)) while a minimum of 1 is required.',)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/base.py:80: UserWarning: No features were selected: either the data is too noisy or the selection test too strict.\n","  UserWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError('Found array with 0 feature(s) (shape=(20000, 0)) while a minimum of 1 is required.',)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/base.py:80: UserWarning: No features were selected: either the data is too noisy or the selection test too strict.\n","  UserWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError('Found array with 0 feature(s) (shape=(20000, 0)) while a minimum of 1 is required.',)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/base.py:80: UserWarning: No features were selected: either the data is too noisy or the selection test too strict.\n","  UserWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError('Found array with 0 feature(s) (shape=(20000, 0)) while a minimum of 1 is required.',)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/base.py:80: UserWarning: No features were selected: either the data is too noisy or the selection test too strict.\n","  UserWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError('Found array with 0 feature(s) (shape=(20000, 0)) while a minimum of 1 is required.',)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=False\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=False\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=False\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=False\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=False\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=False\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=False\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=False\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=False\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=False\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=False\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=False\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=False\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=False\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=False\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=False\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=False\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=False\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l2' and loss='hinge' are not supported when dual=False, Parameters: penalty='l2', loss='hinge', dual=False\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l2' and loss='hinge' are not supported when dual=False, Parameters: penalty='l2', loss='hinge', dual=False\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l2' and loss='hinge' are not supported when dual=False, Parameters: penalty='l2', loss='hinge', dual=False\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l2' and loss='hinge' are not supported when dual=False, Parameters: penalty='l2', loss='hinge', dual=False\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l2' and loss='hinge' are not supported when dual=False, Parameters: penalty='l2', loss='hinge', dual=False\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l2' and loss='hinge' are not supported when dual=False, Parameters: penalty='l2', loss='hinge', dual=False\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l2' and loss='hinge' are not supported when dual=False, Parameters: penalty='l2', loss='hinge', dual=False\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l2' and loss='hinge' are not supported when dual=False, Parameters: penalty='l2', loss='hinge', dual=False\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l2' and loss='hinge' are not supported when dual=False, Parameters: penalty='l2', loss='hinge', dual=False\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l2' and loss='hinge' are not supported when dual=False, Parameters: penalty='l2', loss='hinge', dual=False\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l2' and loss='hinge' are not supported when dual=False, Parameters: penalty='l2', loss='hinge', dual=False\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l2' and loss='hinge' are not supported when dual=False, Parameters: penalty='l2', loss='hinge', dual=False\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l2' and loss='hinge' are not supported when dual=False, Parameters: penalty='l2', loss='hinge', dual=False\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l2' and loss='hinge' are not supported when dual=False, Parameters: penalty='l2', loss='hinge', dual=False\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l2' and loss='hinge' are not supported when dual=False, Parameters: penalty='l2', loss='hinge', dual=False\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l2' and loss='hinge' are not supported when dual=False, Parameters: penalty='l2', loss='hinge', dual=False\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l2' and loss='hinge' are not supported when dual=False, Parameters: penalty='l2', loss='hinge', dual=False\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l2' and loss='hinge' are not supported when dual=False, Parameters: penalty='l2', loss='hinge', dual=False\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/base.py:80: UserWarning: No features were selected: either the data is too noisy or the selection test too strict.\n","  UserWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError('Found array with 0 feature(s) (shape=(20000, 0)) while a minimum of 1 is required.',)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/base.py:80: UserWarning: No features were selected: either the data is too noisy or the selection test too strict.\n","  UserWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError('Found array with 0 feature(s) (shape=(20000, 0)) while a minimum of 1 is required.',)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/base.py:80: UserWarning: No features were selected: either the data is too noisy or the selection test too strict.\n","  UserWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError('Found array with 0 feature(s) (shape=(20000, 0)) while a minimum of 1 is required.',)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/base.py:80: UserWarning: No features were selected: either the data is too noisy or the selection test too strict.\n","  UserWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError('Found array with 0 feature(s) (shape=(20000, 0)) while a minimum of 1 is required.',)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/base.py:80: UserWarning: No features were selected: either the data is too noisy or the selection test too strict.\n","  UserWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError('Found array with 0 feature(s) (shape=(20000, 0)) while a minimum of 1 is required.',)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/base.py:80: UserWarning: No features were selected: either the data is too noisy or the selection test too strict.\n","  UserWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError('Found array with 0 feature(s) (shape=(20000, 0)) while a minimum of 1 is required.',)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/base.py:80: UserWarning: No features were selected: either the data is too noisy or the selection test too strict.\n","  UserWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError('Found array with 0 feature(s) (shape=(20000, 0)) while a minimum of 1 is required.',)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/base.py:80: UserWarning: No features were selected: either the data is too noisy or the selection test too strict.\n","  UserWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError('Found array with 0 feature(s) (shape=(20000, 0)) while a minimum of 1 is required.',)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/base.py:80: UserWarning: No features were selected: either the data is too noisy or the selection test too strict.\n","  UserWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError('Found array with 0 feature(s) (shape=(20000, 0)) while a minimum of 1 is required.',)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/base.py:80: UserWarning: No features were selected: either the data is too noisy or the selection test too strict.\n","  UserWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError('Found array with 0 feature(s) (shape=(20000, 0)) while a minimum of 1 is required.',)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/base.py:80: UserWarning: No features were selected: either the data is too noisy or the selection test too strict.\n","  UserWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError('Found array with 0 feature(s) (shape=(20000, 0)) while a minimum of 1 is required.',)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/base.py:80: UserWarning: No features were selected: either the data is too noisy or the selection test too strict.\n","  UserWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError('Found array with 0 feature(s) (shape=(20000, 0)) while a minimum of 1 is required.',)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/base.py:80: UserWarning: No features were selected: either the data is too noisy or the selection test too strict.\n","  UserWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError('Found array with 0 feature(s) (shape=(20000, 0)) while a minimum of 1 is required.',)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/base.py:80: UserWarning: No features were selected: either the data is too noisy or the selection test too strict.\n","  UserWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError('Found array with 0 feature(s) (shape=(20000, 0)) while a minimum of 1 is required.',)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/base.py:80: UserWarning: No features were selected: either the data is too noisy or the selection test too strict.\n","  UserWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError('Found array with 0 feature(s) (shape=(20000, 0)) while a minimum of 1 is required.',)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/base.py:80: UserWarning: No features were selected: either the data is too noisy or the selection test too strict.\n","  UserWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError('Found array with 0 feature(s) (shape=(20000, 0)) while a minimum of 1 is required.',)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/base.py:80: UserWarning: No features were selected: either the data is too noisy or the selection test too strict.\n","  UserWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError('Found array with 0 feature(s) (shape=(20000, 0)) while a minimum of 1 is required.',)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/base.py:80: UserWarning: No features were selected: either the data is too noisy or the selection test too strict.\n","  UserWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError('Found array with 0 feature(s) (shape=(20000, 0)) while a minimum of 1 is required.',)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/base.py:80: UserWarning: No features were selected: either the data is too noisy or the selection test too strict.\n","  UserWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError('Found array with 0 feature(s) (shape=(20000, 0)) while a minimum of 1 is required.',)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/base.py:80: UserWarning: No features were selected: either the data is too noisy or the selection test too strict.\n","  UserWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError('Found array with 0 feature(s) (shape=(20000, 0)) while a minimum of 1 is required.',)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/base.py:80: UserWarning: No features were selected: either the data is too noisy or the selection test too strict.\n","  UserWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError('Found array with 0 feature(s) (shape=(20000, 0)) while a minimum of 1 is required.',)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/base.py:80: UserWarning: No features were selected: either the data is too noisy or the selection test too strict.\n","  UserWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError('Found array with 0 feature(s) (shape=(20000, 0)) while a minimum of 1 is required.',)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/base.py:80: UserWarning: No features were selected: either the data is too noisy or the selection test too strict.\n","  UserWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError('Found array with 0 feature(s) (shape=(20000, 0)) while a minimum of 1 is required.',)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/base.py:80: UserWarning: No features were selected: either the data is too noisy or the selection test too strict.\n","  UserWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError('Found array with 0 feature(s) (shape=(20000, 0)) while a minimum of 1 is required.',)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/base.py:80: UserWarning: No features were selected: either the data is too noisy or the selection test too strict.\n","  UserWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError('Found array with 0 feature(s) (shape=(20000, 0)) while a minimum of 1 is required.',)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/base.py:80: UserWarning: No features were selected: either the data is too noisy or the selection test too strict.\n","  UserWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError('Found array with 0 feature(s) (shape=(20000, 0)) while a minimum of 1 is required.',)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/base.py:80: UserWarning: No features were selected: either the data is too noisy or the selection test too strict.\n","  UserWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError('Found array with 0 feature(s) (shape=(20000, 0)) while a minimum of 1 is required.',)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=False\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=False\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=False\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=False\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=False\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=False\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=False\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=False\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=False\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=False\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=False\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=False\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=False\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=False\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=False\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=False\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=False\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=False\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l2' and loss='hinge' are not supported when dual=False, Parameters: penalty='l2', loss='hinge', dual=False\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l2' and loss='hinge' are not supported when dual=False, Parameters: penalty='l2', loss='hinge', dual=False\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l2' and loss='hinge' are not supported when dual=False, Parameters: penalty='l2', loss='hinge', dual=False\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l2' and loss='hinge' are not supported when dual=False, Parameters: penalty='l2', loss='hinge', dual=False\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l2' and loss='hinge' are not supported when dual=False, Parameters: penalty='l2', loss='hinge', dual=False\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l2' and loss='hinge' are not supported when dual=False, Parameters: penalty='l2', loss='hinge', dual=False\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l2' and loss='hinge' are not supported when dual=False, Parameters: penalty='l2', loss='hinge', dual=False\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l2' and loss='hinge' are not supported when dual=False, Parameters: penalty='l2', loss='hinge', dual=False\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l2' and loss='hinge' are not supported when dual=False, Parameters: penalty='l2', loss='hinge', dual=False\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l2' and loss='hinge' are not supported when dual=False, Parameters: penalty='l2', loss='hinge', dual=False\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l2' and loss='hinge' are not supported when dual=False, Parameters: penalty='l2', loss='hinge', dual=False\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l2' and loss='hinge' are not supported when dual=False, Parameters: penalty='l2', loss='hinge', dual=False\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l2' and loss='hinge' are not supported when dual=False, Parameters: penalty='l2', loss='hinge', dual=False\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l2' and loss='hinge' are not supported when dual=False, Parameters: penalty='l2', loss='hinge', dual=False\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l2' and loss='hinge' are not supported when dual=False, Parameters: penalty='l2', loss='hinge', dual=False\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l2' and loss='hinge' are not supported when dual=False, Parameters: penalty='l2', loss='hinge', dual=False\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l2' and loss='hinge' are not supported when dual=False, Parameters: penalty='l2', loss='hinge', dual=False\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l2' and loss='hinge' are not supported when dual=False, Parameters: penalty='l2', loss='hinge', dual=False\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError(\"Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\",)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/base.py:80: UserWarning: No features were selected: either the data is too noisy or the selection test too strict.\n","  UserWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError('Found array with 0 feature(s) (shape=(20000, 0)) while a minimum of 1 is required.',)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/base.py:80: UserWarning: No features were selected: either the data is too noisy or the selection test too strict.\n","  UserWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError('Found array with 0 feature(s) (shape=(20000, 0)) while a minimum of 1 is required.',)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/base.py:80: UserWarning: No features were selected: either the data is too noisy or the selection test too strict.\n","  UserWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError('Found array with 0 feature(s) (shape=(20000, 0)) while a minimum of 1 is required.',)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/base.py:80: UserWarning: No features were selected: either the data is too noisy or the selection test too strict.\n","  UserWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError('Found array with 0 feature(s) (shape=(20000, 0)) while a minimum of 1 is required.',)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/base.py:80: UserWarning: No features were selected: either the data is too noisy or the selection test too strict.\n","  UserWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError('Found array with 0 feature(s) (shape=(20000, 0)) while a minimum of 1 is required.',)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/base.py:80: UserWarning: No features were selected: either the data is too noisy or the selection test too strict.\n","  UserWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:479: FitFailedWarning: Classifier fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n","ValueError('Found array with 0 feature(s) (shape=(20000, 0)) while a minimum of 1 is required.',)\n","  \"Details: \\n%r\" % (error_score, e), FitFailedWarning)\n"],"name":"stderr"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-52-e9344fde4de4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m get_best_model_and_accuracy(svc_pipe, \n\u001b[1;32m     21\u001b[0m  \u001b[0msvc_pipe_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m  X, y) \n\u001b[0m","\u001b[0;32m<ipython-input-1-31398e513021>\u001b[0m in \u001b[0;36mget_best_model_and_accuracy\u001b[0;34m(model, params, X, y)\u001b[0m\n\u001b[1;32m      6\u001b[0m                         \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# 要搜索的参数\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m                         error_score=0.) # 如果报错 结果是0\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 拟合模型和参数\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;31m# 经典的精度\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Best Accuracy: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    637\u001b[0m                                   error_score=self.error_score)\n\u001b[1;32m    638\u001b[0m           for parameters, (train, test) in product(candidate_params,\n\u001b[0;32m--> 639\u001b[0;31m                                                    cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m         \u001b[0;31m# if one choose to see train score, \"out\" will contain train score info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    777\u001b[0m             \u001b[0;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    623\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 625\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    586\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0mcb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 588\u001b[0;31m         \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    589\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, error_score)\u001b[0m\n\u001b[1;32m    456\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    246\u001b[0m             \u001b[0mThis\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m         \"\"\"\n\u001b[0;32m--> 248\u001b[0;31m         \u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    211\u001b[0m                 Xt, fitted_transformer = fit_transform_one_cached(\n\u001b[1;32m    212\u001b[0m                     \u001b[0mcloned_transformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m                     **fit_params_steps[name])\n\u001b[0m\u001b[1;32m    214\u001b[0m                 \u001b[0;31m# Replace the transformer of the step with the fitted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                 \u001b[0;31m# transformer. This is necessary when loading the transformer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/memory.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 362\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall_and_shelve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_fit_transform_one\u001b[0;34m(transformer, weight, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    579\u001b[0m                        **fit_params):\n\u001b[1;32m    580\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'fit_transform'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 581\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    582\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    518\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    522\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/feature_selection/from_model.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    167\u001b[0m                 \"Since 'prefit=True', call transform directly\")\n\u001b[1;32m    168\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/svm/classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    233\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpenalty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdual\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmulti_class\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m             self.loss, sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmulti_class\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"crammer_singer\"\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py\u001b[0m in \u001b[0;36m_fit_liblinear\u001b[0;34m(X, y, C, fit_intercept, intercept_scaling, class_weight, penalty, dual, verbose, max_iter, tol, random_state, multi_class, loss, epsilon, sample_weight)\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_ind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misspmatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolver_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    889\u001b[0m         \u001b[0mclass_weight_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrnd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'i'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 890\u001b[0;31m         epsilon, sample_weight)\n\u001b[0m\u001b[1;32m    891\u001b[0m     \u001b[0;31m# Regarding rnd.randint(..) in the above signature:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    892\u001b[0m     \u001b[0;31m# seed for srand in range [0..INT_MAX); due to limitations in Numpy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]}]}